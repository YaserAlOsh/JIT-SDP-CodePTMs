{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.696483700Z",
     "start_time": "2023-06-10T12:14:52.391212500Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers, tokenizers, torch, datasets\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.712484700Z",
     "start_time": "2023-06-10T12:14:58.703481800Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers=4.31.0\n",
      "tokenizers=0.11.0\n",
      "torch=1.13.1\n",
      "datasets=2.10.1\n"
     ]
    }
   ],
   "source": [
    "print('transformers={}'.format(transformers.__version__))\n",
    "print('tokenizers={}'.format(tokenizers.__version__))\n",
    "print('torch={}'.format(torch.__version__))\n",
    "print('datasets={}'.format(datasets.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.786483300Z",
     "start_time": "2023-06-10T12:14:58.720478300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:15:31.884556300Z",
     "start_time": "2023-06-10T12:15:31.823559900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def defect_percent(df):\n",
    "    return df['label'].sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest_versions = ['base','full_change','special_tokens']\n",
    "models_names = ['bilstm','codebert','codereviewer','javabert','codet5p']\n",
    "fine_tuning_techniques = ['full','partial','lora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_message=True\n",
    "include_metrics=False\n",
    "use_lora = False\n",
    "ft_technique = fine_tuning_techniques[1]\n",
    "lsg_attention = False\n",
    "copy_embedding_from_model=True\n",
    "print_for_debug = False\n",
    "max_commit_code_length = 512\n",
    "partial_trained_encoders = 3\n",
    "model_name = models_names[1]\n",
    "dataset_version_name = datatest_versions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_lsg_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'base'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "multiple_files = True\n",
    "data_name = 'apache_jit'\n",
    "prefix = '<java> '\n",
    "columns_to_remove = ['id','msg','code','metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:19:55.033495500Z",
     "start_time": "2023-06-10T12:19:43.529014400Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/host2-virtualmachine1/.cache/huggingface/datasets/csv/default-2b5baf67d918b518/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "Found cached dataset csv (/home/host2-virtualmachine1/.cache/huggingface/datasets/csv/default-5c559d330a4271fa/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"csv\",data_files=f'datasets/{data_name}/train_v{version}_shuffled.csv', streaming=True,split=\"train\")\n",
    "valid_dataset = load_dataset(\"csv\",data_files=f'datasets/{data_name}/valid_v{version}_balanced.csv',split=\"train\")\n",
    "test_dataset = load_dataset(\"csv\",data_files=f'datasets/{data_name}/test_v{version}.csv',split=\"train\")\n",
    "train_df = pd.read_csv(f'datasets/{data_name}/train_v{version}_shuffled.csv')\n",
    "valid_df = pd.read_csv(f'datasets/{data_name}/valid_v{version}_balanced.csv')\n",
    "test_df = pd.read_csv(f'datasets/{data_name}/test_v{version}.csv')\n",
    "train_length = train_df.shape[0]\n",
    "valid_length = valid_df.shape[0]\n",
    "test_length  = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:19:55.070499600Z",
     "start_time": "2023-06-10T12:19:55.027250200Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c548a3d335dc4fcc2c1012a5d3f0f956feff7276</td>\n",
       "      <td>0</td>\n",
       "      <td>[FLINK-11549][tests] Remove obsolete ResourceM...</td>\n",
       "      <td>[['&lt;del&gt; package org.apache.flink.runtime.clus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a02e8e0f9fde8372ff0eea0e674f72bb8be15875</td>\n",
       "      <td>1</td>\n",
       "      <td>ZEPPELIN-3876. Unable to rename note\\n\\n### Wh...</td>\n",
       "      <td>[['&lt;del&gt; if (isRelative) {', '&lt;add&gt; if (isRela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98184bd078d7b957f4cf99d26a5aacef1583fe3a</td>\n",
       "      <td>0</td>\n",
       "      <td>[FLINK-12401][table] Support incremental emit ...</td>\n",
       "      <td>[['&lt;add&gt; import org.apache.flink.util.Collecto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>045b8da502328e72976d9e3aeb79a50090596bda</td>\n",
       "      <td>1</td>\n",
       "      <td>HIVE-16642 : New Events created as part of rep...</td>\n",
       "      <td>[['&lt;add&gt; package org.apache.hive.hcatalog.api....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2f1b3eab675ac327a6f61b724d5f0bce01ec6e68</td>\n",
       "      <td>1</td>\n",
       "      <td>HBASE-19998 Flakey TestVisibilityLabelsWithDef...</td>\n",
       "      <td>[['&lt;add&gt; LOG.info(\"REMOVE\", new Throwable(\"REM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label  \\\n",
       "0  c548a3d335dc4fcc2c1012a5d3f0f956feff7276      0   \n",
       "1  a02e8e0f9fde8372ff0eea0e674f72bb8be15875      1   \n",
       "2  98184bd078d7b957f4cf99d26a5aacef1583fe3a      0   \n",
       "3  045b8da502328e72976d9e3aeb79a50090596bda      1   \n",
       "4  2f1b3eab675ac327a6f61b724d5f0bce01ec6e68      1   \n",
       "\n",
       "                                                 msg  \\\n",
       "0  [FLINK-11549][tests] Remove obsolete ResourceM...   \n",
       "1  ZEPPELIN-3876. Unable to rename note\\n\\n### Wh...   \n",
       "2  [FLINK-12401][table] Support incremental emit ...   \n",
       "3  HIVE-16642 : New Events created as part of rep...   \n",
       "4  HBASE-19998 Flakey TestVisibilityLabelsWithDef...   \n",
       "\n",
       "                                                code  \n",
       "0  [['<del> package org.apache.flink.runtime.clus...  \n",
       "1  [['<del> if (isRelative) {', '<add> if (isRela...  \n",
       "2  [['<add> import org.apache.flink.util.Collecto...  \n",
       "3  [['<add> package org.apache.hive.hcatalog.api....  \n",
       "4  [['<add> LOG.info(\"REMOVE\", new Throwable(\"REM...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:32.352337400Z",
     "start_time": "2023-06-10T14:21:32.340333Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name == 'bilstm'\n",
    "    model_checkpoint = 'microsoft/codereviewer'\n",
    "elif model_name == 'codebert':\n",
    "    model_checkpoint = 'microsoft/codebert-base'\n",
    "elif model_name == 'javabert':\n",
    "    model_checkpoint = 'CAUKiel/JavaBERT'\n",
    "elif model_name == 'codereviewer':\n",
    "    model_checkpoint = 'microsoft/codereviewer'\n",
    "else:\n",
    "    model_checkpoint = 'Salesforce/codet5p-220m'\n",
    "if lsg_attention:\n",
    "    if os.path.exists(\"{}_lsg_{}\".format(model_name,max_commit_code_length)):\n",
    "        model_checkpoint = \"{}_lsg_{}\".format(model_name,max_commit_code_length)\n",
    "    else:\n",
    "        create_lsg_model = True\n",
    "model_name_suffix = model_name + '_{}{}{}{}_{}'.format(max_commit_code_length,'_msg' if include_message else '','_mtc' if include_metrics else '', '_lsg' if lsg_attention else '', '_lora' if use_lora else '',dataset_version_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'javabert':\n",
    "    cls_token = '[CLS]'\n",
    "    sep_token = '[SEP]'\n",
    "    msg_token = '<msg>'\n",
    "    metrics_token = '[CLS]'\n",
    "    code_change_token = '[CLS]'\n",
    "else:\n",
    "    cls_token = '<s>'\n",
    "    sep_token = '</s>'\n",
    "    msg_token = '<msg>'\n",
    "    metrics_token = '<s>''\n",
    "    code_change_token = '<s>'\n",
    "if dataset_version_name == 'special_tokens':\n",
    "    added_token = '<added>'\n",
    "    removed_token = '<removed>'\n",
    "else:\n",
    "    added_token = '<add>'\n",
    "    removed_token = '<del>'\n",
    "prefix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tokens_to_tokenizer(tokenizer):\n",
    "    if dataset_version_name == 'special_tokens':\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[added_token, removed_token,'<STR>','<NUM>']})\n",
    "    if include_message:\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[cls_token, sep_token,'<pad>', '<unk>',added_token, removed_token,msg_token]})\n",
    "    else:\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[cls_token, sep_token,'<pad>', '<unk>',added_token, removed_token]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if create_lsg_model:\n",
    "    from lsg_converter import LSGConverter\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    converter = LSGConverter(max_sequence_length=max_commit_code_length)\n",
    "    if model_name == 'javabert':\n",
    "        architecture = 'RobertaForSequenceClassification'\n",
    "    elif model_name == 'codebert':\n",
    "        architecture = 'RobertaForSequenceClassification'\n",
    "    else:\n",
    "        print('Error! LSG Attention not supported for T5 models at the moment. (CodeReviewer and CodeT5+)')\n",
    "        exit()\n",
    "    model, tokenizer = converter.convert_from_pretrained(model_checkpoint,dropout=0.2,hidden_dropout_prob=0.2,num_labels=2,architecture=architecture)\n",
    "    add_tokens_to_tokenizer(tokenizer)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    save_path = '{}_lsg_{}'.format(model_name,max_commit_code_length)\n",
    "    model_checkpoint = save_path\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T13:09:11.104765600Z",
     "start_time": "2023-06-10T13:09:10.300734300Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from bi_lstm import BiLSTM\n",
    "if model_name == 'bilstm':\n",
    "    if copy_embedding_from_model:\n",
    "        tokenizer = AutoTokenizer.from_pretrained( model_checkpoint)\n",
    "    else:\n",
    "        from transformers import RobertaTokenizerFast\n",
    "        tokenizer_name = '{}_{}_bpe'.format(data_name,vocab_size)\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained('./BPE_tokenizer/{}'.format(tokenizer_name),max_len=max_commit_code_length)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained( model_checkpoint)\n",
    "add_tokens_to_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T13:09:48.182646700Z",
     "start_time": "2023-06-10T13:09:48.135006100Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 2, 2], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if print_for_debug:\n",
    "    print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.787490400Z",
     "start_time": "2023-06-10T12:14:58.741490600Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_empty(seq):\n",
    "    return list(filter(lambda s: s != None and s != '',seq))\n",
    "\n",
    "\n",
    "def join_commit_codes_sep(commit,commit_start=' <NFILE> ',file_sep=' <NFILE> ',line_sep=' <NLINE> '):\n",
    "    if type(commit) == str:\n",
    "        commit = eval(commit)\n",
    "    #return commit_start + file_sep.join(remove_empty([line_sep.join([correct_token(line.split(' ')[0]) +' ' + ' '.join(line.split(' ')[1:]) for line in file]) for file in commit]))\n",
    "    return commit_start + file_sep.join(remove_empty([line_sep.join(file) for file in commit]))\n",
    "\n",
    "def join_commit_codes(commit):\n",
    "    return join_commit_codes_sep(commit,prefix ,f' {sep_token} ','\\n')\n",
    "    #return join_commit_codes_sep(commit,cls_token+' ',f' {sep_token} ',' ')\n",
    "def join_file_lines(file):\n",
    "    if type(file) != list:\n",
    "        file = eval(file)\n",
    "    return prefix +  '\\n'.join(file)\n",
    "\n",
    "def empty_join_commit_codes(commit):\n",
    "    return join_commit_codes_sep(commit,'','')\n",
    "def join_lines(lines,commit_start=' <NFILE> ',line_sep=' <NLINE> '):\n",
    "    return commit_start + line_sep.join(lines)\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "def join_commit_msg_and_code(msg,code):\n",
    "    if msg is None:\n",
    "        msg = ''\n",
    "    if code is None:\n",
    "        code = ''\n",
    "    return msg_token + ' ' + msg.split('\\n')[0] + ' ' + code_change_token + ' ' + join_commit_codes_sep(code ,'',f' {sep_token} ','\\n')\n",
    "def join_commit_msg_metrics_code(msg,mtc,code):\n",
    "    if msg is None:\n",
    "        msg = ''\n",
    "    if code is None:\n",
    "        code = ''\n",
    "    if mtc is None:\n",
    "        mtc = ''\n",
    "    return msg_token + ' ' + msg.split('\\n')[0] + '\\n' + metrics_token + ' ' + mtc + '\\n' + code_change_token + ' ' + join_commit_codes_sep(code ,'',f' {sep_token} ','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:20:03.435005200Z",
     "start_time": "2023-06-10T12:20:03.394801900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode(batch):\n",
    "    if multiple_files:\n",
    "        if include_message:\n",
    "            if include_metrics:\n",
    "                inputs = tokenizer(list(map(join_commit_msg_metrics_code,batch['msg'],batch['metrics'],batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "            else:\n",
    "                inputs = tokenizer(list(map(join_commit_msg_and_code,batch['msg'],batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "        elif include_metrics:\n",
    "            inputs = tokenizer(list(map(join_commit_msg_and_code,batch['metrics'],batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "        else:\n",
    "            inputs = tokenizer(list(map(join_commit_codes,batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "    else:    \n",
    "        inputs = tokenizer(list(map(join_file_lines,batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:37.146079600Z",
     "start_time": "2023-06-10T14:21:37.126280Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 15:18:46.435917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,max_length=max_commit_code_length,padding='longest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model classes and initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:20:27.676150600Z",
     "start_time": "2023-06-10T12:20:27.652146Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T13:58:32.229044800Z",
     "start_time": "2023-06-10T13:58:30.381801400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50268, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel,AutoModelForSequenceClassification, AutoConfig\n",
    "if model_name == 'bilstm':\n",
    "    model = BiLSTM(len(tokenizer),embed_size=768,hidden_size=64,lstm_layers=4,dropout=0.2,padding_id=tokenizer.pad_token_id)\n",
    "    if copy_embedding_from_model:\n",
    "        copy_from_model = AutoModel.from_pretrained(model_checkpoint)\n",
    "        with torch.no_grad():\n",
    "            model.embedding.weight.copy_(copy_from_model.encoder.embed_tokens.weight)\n",
    "            model.embedding.require_grad = False\n",
    "else:\n",
    "    config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "    config.hidden_dropout_prob = 0.2\n",
    "    config.dropout = 0.2\n",
    "    config.num_labels=2\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,config=config)\n",
    "\n",
    "    #change embedding layer size to match tokenizer vocabulary size (Because we added new tokens to the tokenizer):\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50268, 768)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if print_for_debug:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ft_technique == 'lora':\n",
    "    from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS, inference_mode=False, r=16, lora_alpha=16, lora_dropout=0.1, bias=\"all\"\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "elif ft_technique == 'partial':\n",
    "    # freeze encoder layers except the last 2 layers\n",
    "    modules = []\n",
    "    trained_encoder_layers = partial_trained_encoders\n",
    "    if model_name == 'codebert':\n",
    "        modules = [model.roberta.embeddings, *model.roberta.encoder.layer[:-trained_encoder_layers]]\n",
    "    elif model_name == 'javabert' \n",
    "        modules = [model.bert.embeddings, *model.bert.encoder.layer[:-trained_encoder_layers]]\n",
    "    elif model_name == 'codereviewer' or model_name == 'codet5p':\n",
    "        modules = [model.shared, *model.encoder.block[:-trained_encoder_layers]]\n",
    "    for module in modules:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14767874\n",
      "124649474\n"
     ]
    }
   ],
   "source": [
    "def param_count(model,trainable_only=True):\n",
    "    return sum([p.numel()for p in model.parameters() if p.requires_grad or not trainable_only])\n",
    "if print_for_debug:\n",
    "    print(param_count(model))\n",
    "    print(param_count(model,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:03:52.745412600Z",
     "start_time": "2023-06-10T14:03:52.715422800Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "def roc_auc(preds,target):\n",
    "    roc_auc_score(target, preds)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    _predictions = p.predictions\n",
    "    _labels = p.label_ids\n",
    "    _predictions = np.argmax(_predictions, axis=-1)\n",
    "    vals = {}\n",
    "    vals['accuracy'] = accuracy_score(_labels, _predictions)\n",
    "    vals['f1'] = f1_score(_labels, _predictions)\n",
    "    vals['precision'] = precision_score(_labels, _predictions)\n",
    "    vals['recall'] = recall_score(_labels, _predictions)\n",
    "    vals['matthews_correlation'] = matthews_corrcoef(_labels, _predictions)\n",
    "    vals['auc'] = roc_auc_score(_labels, _predictions.reshape(-1,1))\n",
    "    return  vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:05:59.514455600Z",
     "start_time": "2023-06-10T14:05:59.501453Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW\n",
    "from transformers import Trainer,get_linear_schedule_with_warmup\n",
    "from math import ceil\n",
    "init_lr,head_lr = 5e-4 ,1e-4\n",
    "adam_eps = 1e-6\n",
    "weight_decay = 0.01\n",
    "epochs=10\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 8\n",
    "batch_steps = int(train_length/(batch_size*gradient_accumulation_steps))\n",
    "#rem_steps = train_length%(batch_size*gradient_accumulation_steps)\n",
    "rem_steps = ceil((train_length%(batch_size*gradient_accumulation_steps)) / batch_size)\n",
    "train_steps = (epochs) * (batch_steps + rem_steps)\n",
    "warmpup_factor = 0.25\n",
    "warmpup_steps = int(train_steps*warmpup_factor)\n",
    "optim = 'adafactor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:04:34.950969100Z",
     "start_time": "2023-06-10T14:03:54.867449100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/host2-virtualmachine1/.cache/huggingface/datasets/csv/default-2b5baf67d918b518/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-f32eac4c6c9bd6ad.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(encode, batch_size=batch_size,batched=True, remove_columns=columns_to_remove)\n",
    "valid_dataset = valid_dataset.map(encode, batch_size=batch_size,batched=True, remove_columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 50267, 646, 7613, 23617, 12, 15314, 3414, 46386, 47173, 742, 27336, 29707, 13877, 44854, 2068, 38834, 1437, 0, 1437, 50266, 3737, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 3998, 10504, 48019, 131, 50118, 50266, 6595, 18735, 2348, 4, 24625, 4, 40448, 36383, 131, 50118, 50266, 6595, 18735, 2348, 4, 21959, 23199, 4, 32379, 34603, 29233, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 43163, 27975, 4, 49602, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 677, 2348, 4, 33282, 2348, 41967, 5290, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 3998, 10504, 48019, 4, 41817, 4, 47279, 2688, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 3530, 39798, 4, 18522, 49054, 39868, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 3530, 39798, 4, 13424, 1999, 4, 35804, 17452, 4, 42578, 42495, 24017, 39868, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 48768, 4, 40448, 37155, 1970, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 48768, 4, 48362, 41602, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 38177, 3443, 4, 250, 47678, 21945, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 45025, 37096, 4, 47744, 44854, 46571, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 38177, 3443, 4, 45366, 40169, 3443, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 33959, 41967, 5290, 4, 47446, 41967, 5290, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 21959, 49320, 4, 47446, 47279, 44854, 131, 50118, 50266, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 32843, 4, 34603, 23345, 2403, 131, 50118, 50266, 6595, 31118, 4, 267, 19304, 4, 4993, 131, 50118, 50266, 6595, 31118, 4, 267, 19304, 4, 4993, 21527, 131, 50118, 50266, 6595, 31118, 4, 267, 19304, 4, 17206, 131, 50118, 50266, 6595, 31118, 4, 267, 19304, 4, 17206, 21527, 131, 50118, 50266, 6595, 31118, 4, 267, 19304, 4, 34603, 131, 50118, 50266, 6595, 2850, 2331, 4, 46550, 131, 50118, 50266, 6595, 46900, 4, 32843, 4, 8138, 24192, 131, 50118, 50266, 6595, 25156, 31118, 4, 267, 19304, 4, 26039, 2399, 4, 46346, 28568, 1536, 131, 50118, 50266, 6595, 25156, 31118, 4, 267, 19304, 4, 26039, 2399, 4, 46346, 36948, 131, 50118, 50266, 6595, 25156, 31118, 4, 119, 3343, 4842, 4, 448, 3343, 4842, 4, 119, 3343, 131, 50118, 50266, 6595, 25156, 31118, 4, 119, 3343, 4842, 4, 448, 3343, 4842, 4, 14746, 131, 50118, 50266, 285, 1380, 13877, 44854, 2068, 38834, 14269, 4500, 23345, 2403, 25522, 50118, 50266, 940, 25156, 11848, 36383, 467, 131, 50118, 50266, 940, 25156, 47048, 40220, 5457, 92, 47048, 47006, 50118, 50266, 940, 755, 49054, 39868, 239, 49054, 39868, 131, 50118, 50266, 787, 17206, 21527, 50118, 50266, 285, 25156, 13842, 11808, 43048, 25522, 50118, 50266, 467, 5457, 3773, 2348, 41967, 5290, 4, 32845, 40448, 36383, 1640, 33282, 2348, 41967, 2]\n",
      "0\n",
      "<s><msg> [FLINK-11549][tests] Remove obsolete ResourceManagerITCase <s> <del> package org.apache.flink.runtime.clusterframework;\n",
      "<del> import akka.actor.ActorSystem;\n",
      "<del> import akka.testkit.JavaTestKit;\n",
      "<del> import org.apache.flink.configuration.Configuration;\n",
      "<del> import org.apache.flink.runtime.akka.AkkaUtils;\n",
      "<del> import org.apache.flink.runtime.clusterframework.types.ResourceID;\n",
      "<del> import org.apache.flink.runtime.highavailability.HighAvailabilityServices;\n",
      "<del> import org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedHaServices;\n",
      "<del> import org.apache.flink.runtime.instance.ActorGateway;\n",
      "<del> import org.apache.flink.runtime.instance.HardwareDescription;\n",
      "<del> import org.apache.flink.runtime.messages.Acknowledge;\n",
      "<del> import org.apache.flink.runtime.taskmanager.TaskManagerLocation;\n",
      "<del> import org.apache.flink.runtime.messages.RegistrationMessages;\n",
      "<del> import org.apache.flink.runtime.testingUtils.TestingUtils;\n",
      "<del> import org.apache.flink.runtime.testutils.TestingResourceManager;\n",
      "<del> import org.apache.flink.util.TestLogger;\n",
      "<del> import org.junit.After;\n",
      "<del> import org.junit.AfterClass;\n",
      "<del> import org.junit.Before;\n",
      "<del> import org.junit.BeforeClass;\n",
      "<del> import org.junit.Test;\n",
      "<del> import scala.Option;\n",
      "<del> import java.util.Arrays;\n",
      "<del> import static org.junit.Assert.assertEquals;\n",
      "<del> import static org.junit.Assert.assertTrue;\n",
      "<del> import static org.mockito.Mockito.mock;\n",
      "<del> import static org.mockito.Mockito.when;\n",
      "<del> public class ResourceManagerITCase extends TestLogger {\n",
      "<del> private static ActorSystem system;\n",
      "<del> private static Configuration config = new Configuration();\n",
      "<del> private HighAvailabilityServices highAvailabilityServices;\n",
      "<del> @BeforeClass\n",
      "<del> public static void setup() {\n",
      "<del> system = AkkaUtils.createActorSystem(AkkaUt</s>\n",
      "[0, 50267, 525, 9662, 510, 3721, 2444, 12, 3170, 5067, 4, 39226, 7, 38453, 1591, 1437, 0, 1437, 50266, 114, 36, 354, 29806, 3693, 43, 25522, 50118, 50265, 114, 36, 354, 29806, 3693, 48200, 27785, 32903, 4, 6460, 46102, 42119, 49123, 8198, 1536, 46469, 47770, 35122, 25522, 50118, 1437, 2, 1437, 50265, 860, 25522, 50118, 50265, 39277, 4, 37785, 1640, 46456, 2072, 42394, 1640, 4651, 32236, 1640, 5733, 4, 46734, 1215, 48050, 322, 9179, 46469, 23999, 1297, 364, 4, 6460, 42394, 43048, 35122, 4397, 50118, 50265, 35524, 2916, 36, 6454, 48847, 1437, 44882, 43, 25522, 50118, 50265, 34772, 4, 44223, 46469, 48237, 7, 2142, 5849, 8574, 1297, 1437, 44882, 4397, 50118, 50265, 35524, 50118, 1437, 2, 1437, 50266, 6068, 1591, 176, 5457, 27276, 32537, 4, 32845, 27728, 46469, 73, 48811, 1215, 306, 73, 32903, 176, 1297, 22, 21959, 1297, 5377, 6, 46557, 4397, 50118, 50265, 6068, 1591, 176, 5457, 27276, 32537, 4, 32845, 27728, 46469, 73, 32903, 176, 1297, 22, 21959, 1297, 5377, 6, 46557, 4397, 50118, 50265, 18821, 1640, 49499, 4397, 50118, 50265, 27276, 32537, 4, 2558, 4344, 27728, 1640, 32903, 176, 4, 6460, 28081, 49196, 22, 4651, 1215, 32903, 176, 1297, 1528, 6, 5377, 6, 46557, 4397, 50118, 50265, 12881, 1640, 49499, 322, 261, 42697, 1640, 32903, 176, 6, 5377, 4397, 50118, 50265, 18088, 28568, 1536, 46469, 4651, 1215, 32903, 176, 1297, 1591, 176, 4, 6460, 31723, 49291, 50118, 50266, 27276, 32537, 4, 46327, 27728, 1640, 32903, 134, 4, 6460, 28081, 49196, 5377, 6, 46557, 4397, 50118, 50265, 27276, 32537, 4, 46327, 27728, 1640, 32903, 176, 4, 6460, 28081, 49196, 5377, 6, 46557, 4397, 50118, 50266, 2775, 39863, 5457, 27276, 32537, 4, 46327, 49262, 46469, 73, 48811, 1215, 306, 1297, 5377, 6, 46557, 4397, 50118, 50265, 2775, 39863, 5457, 27276, 32537, 4, 46327, 49262, 46469, 73, 48811, 1215, 246, 1297, 5377, 6, 46557, 4397, 50118, 1437, 2, 1437, 50265, 114, 48209, 32903, 42119, 4, 620, 7870, 3908, 46469, 47770, 35122, 25522, 50118, 50265, 3211, 92, 47376, 48847, 1640, 34222, 4, 34609, 46469, 32903, 42119, 128, 207, 29, 108, 16, 45, 554, 19, 48817, 108, 1297, 1591, 42119, 48749, 50118, 50265, 35524, 50118, 50265, 114, 48209, 4651, 27728, 42119, 4, 620, 7870, 3908, 46469, 47770, 35122, 25522, 50118, 50265, 3211, 92, 47376, 48847, 1640, 34222, 4, 34609, 46469, 4651, 27728, 42119, 128, 207, 29, 108, 16, 45, 554, 19, 48817, 108, 1297, 92, 27728, 42119, 48749, 50118, 50265, 35524, 50118, 50265, 114, 36, 4651, 27728, 42119, 4, 620, 7870, 3908, 46469, 42326, 49293, 25522, 50118, 50265, 3211, 92, 47376, 48847, 1640, 34222, 4, 34609, 46469, 4651, 27728, 42119, 128, 207, 29, 108, 16, 554, 19, 128, 42326, 108, 1297, 92, 27728, 42119, 48749, 50118, 50265, 35524, 50118, 50265, 114, 48209, 4651, 49262, 42119, 4, 620, 7870, 3908, 46469, 47770, 35122, 25522, 50118, 50265, 3211, 92, 47376, 48847, 1640, 34222, 4, 34609, 46469, 4651, 49262, 42119, 128, 207, 29, 108, 16, 45, 554, 19, 48817, 108, 1297, 92, 49262, 42119, 48749, 50118, 50265, 35524, 50118, 50265, 114, 36, 4651, 49262, 42119, 4, 620, 7870, 3908, 46469, 42326, 49293, 25522, 50118, 50265, 2]\n",
      "1\n",
      "<s><msg> ZEPPELIN-3876. Unable to rename note <s> <del> if (isRelative) {\n",
      "<add> if (isRelative &&!note.getParentPath().equals(\"/\")) {\n",
      " </s> <add> try {\n",
      "<add> conn.send(serializeMessage(new Message(OP.ERROR_INFO).put(\"info\", e.getMessage())));\n",
      "<add> } catch (IOException iox) {\n",
      "<add> LOG.error(\"Fail to send error info\", iox);\n",
      "<add> }\n",
      " </s> <del> Note note2 = notebookService.createNote(\"/folder_4/note2\", \"test\", context, callback);\n",
      "<add> Note note2 = notebookService.createNote(\"/note2\", \"test\", context, callback);\n",
      "<add> reset(callback);\n",
      "<add> notebookService.renameNote(note2.getId(), \"new_note2\", true, context, callback);\n",
      "<add> verify(callback).onSuccess(note2, context);\n",
      "<add> assertEquals(\"new_note2\", note2.getName());\n",
      "<del> notebookService.removeNote(note1.getId(), context, callback);\n",
      "<add> notebookService.removeNote(note2.getId(), context, callback);\n",
      "<del> notesInfo = notebookService.removeFolder(\"/folder_4\", context, callback);\n",
      "<add> notesInfo = notebookService.removeFolder(\"/folder_3\", context, callback);\n",
      " </s> <add> if (!notePath.startsWith(\"/\")) {\n",
      "<add> throw new RuntimeException(String.format(\"notePath '%s' is not started with '/'\", notePath));\n",
      "<add> }\n",
      "<add> if (!newNotePath.startsWith(\"/\")) {\n",
      "<add> throw new RuntimeException(String.format(\"newNotePath '%s' is not started with '/'\", newNotePath));\n",
      "<add> }\n",
      "<add> if (newNotePath.startsWith(\"//\")) {\n",
      "<add> throw new RuntimeException(String.format(\"newNotePath '%s' is started with '//'\", newNotePath));\n",
      "<add> }\n",
      "<add> if (!newFolderPath.startsWith(\"/\")) {\n",
      "<add> throw new RuntimeException(String.format(\"newFolderPath '%s' is not started with '/'\", newFolderPath));\n",
      "<add> }\n",
      "<add> if (newFolderPath.startsWith(\"//\")) {\n",
      "<add></s>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 50267, 646, 7613, 23617, 12, 22960, 2663, 46386, 14595, 742, 7737, 16548, 29901, 223, 5438, 27814, 15664, 5745, 13, 786, 12, 42996, 5230, 19920, 46498, 41101, 15, 9513, 21013, 4, 1437, 0, 1437, 50265, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 32843, 4, 44252, 368, 131, 50118, 50266, 1009, 1437, 1437, 1437, 1437, 28696, 3572, 15698, 991, 405, 33977, 49138, 3572, 15698, 50118, 50265, 1009, 1437, 1437, 1437, 1437, 28696, 3572, 15698, 991, 405, 33977, 50, 29901, 39962, 3908, 27814, 15664, 49138, 3572, 15698, 50118, 50265, 1009, 28696, 5234, 15698, 50118, 50265, 1009, 25522, 1039, 20414, 50118, 50265, 1009, 28277, 358, 86, 77, 41, 40796, 898, 197, 28, 1468, 1538, 4, 20, 1835, 923, 115, 50118, 50265, 1009, 28, 1169, 41, 419, 8, 20044, 898, 36, 28030, 3435, 37141, 25, 414, 5240, 43, 50, 5, 507, 50118, 50265, 1009, 898, 9, 5, 40796, 4, 50118, 50265, 1009, 50118, 50265, 1009, 22248, 31, 29901, 33977, 6, 29901, 39962, 3908, 27814, 15664, 16, 341, 7, 29901, 3266, 14, 33, 57, 4752, 4, 50118, 50265, 1009, 152, 5448, 39512, 414, 30401, 2368, 11, 31914, 5745, 6, 939, 4, 242, 482, 683, 89, 16, 41, 2935, 6, 52, 33, 50118, 50265, 1009, 7, 31914, 793, 2189, 137, 3981, 92, 4752, 1980, 4, 20, 29901, 39962, 3908, 27814, 15664, 5448, 40, 28, 50118, 50265, 1009, 341, 11, 12832, 7, 5, 29901, 33977, 5448, 114, 258, 6448, 32, 6533, 11, 5, 2103, 13884, 50118, 50265, 1009, 5043, 6, 142, 5, 5448, 16, 3032, 7, 28, 55, 5693, 87, 29901, 33977, 25, 24, 64, 4195, 50118, 50265, 1009, 3266, 30401, 2368, 4, 50118, 50265, 1009, 50118, 50265, 1009, 40206, 35, 33232, 26122, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 5, 33232, 26122, 61, 6308, 5, 595, 26683, 1070, 775, 50118, 50265, 1009, 40206, 35, 66, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 5, 31914, 868, 22779, 341, 7, 4195, 414, 4, 7627, 5555, 5448, 50118, 50265, 1009, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 7, 4195, 1640, 4917, 43, 2189, 8, 304, 31914, 5448, 7, 31914, 1640, 46888, 43, 50118, 50265, 1009, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 2189, 4, 50118, 50265, 1009, 50118, 50265, 1009, 285, 13842, 29901, 39962, 3908, 27814, 15664, 1640, 21678, 33232, 26122, 6, 9944, 15664, 868, 44252, 368, 41552, 565, 15698, 66, 43, 50118, 50265, 1009, 35524, 50118, 50265, 1009, 49703, 5234, 15698, 50118, 50265, 1009, 50118, 50265, 285, 12332, 9944, 15664, 868, 44252, 368, 41552, 565, 15698, 14269, 38934, 41552, 565, 15698, 25522, 50118, 50265, 13842, 31914, 1640, 565, 638, 4397, 50118, 50265, 35524, 50118, 2]\n",
      "0\n",
      "<s><msg> [FLINK-12401][table] Support incremental emit under AccRetract mode for non-window streaming FlatAggregate on Table API. <s> <add> import org.apache.flink.util.Collector;\n",
      "<del> *     <li>emitValue</li>\n",
      "<add> *     <li>emitValue or emitUpdateWithRetract</li>\n",
      "<add> * <pre>\n",
      "<add> * {@code\n",
      "<add> * Called every time when an aggregation result should be materialized. The returned value could\n",
      "<add> * be either an early and incomplete result (periodically emitted as data arrive) or the final\n",
      "<add> * result of the aggregation.\n",
      "<add> *\n",
      "<add> * Different from emitValue, emitUpdateWithRetract is used to emit values that have been updated.\n",
      "<add> * This method outputs data incrementally in retract mode, i.e., once there is an update, we have\n",
      "<add> * to retract old records before sending new updated ones. The emitUpdateWithRetract method will be\n",
      "<add> * used in preference to the emitValue method if both methods are defined in the table aggregate\n",
      "<add> * function, because the method is treated to be more efficient than emitValue as it can output\n",
      "<add> * values incrementally.\n",
      "<add> *\n",
      "<add> * param: accumulator           the accumulator which contains the current aggregated results\n",
      "<add> * param: out                   the retractable collector used to output data. Use collect method\n",
      "<add> *                              to output(add) records and use retract method to retract(delete)\n",
      "<add> *                              records.\n",
      "<add> *\n",
      "<add> * public void emitUpdateWithRetract(ACC accumulator, RetractableCollector<T> out)\n",
      "<add> * }\n",
      "<add> * </pre>\n",
      "<add> *\n",
      "<add> public interface RetractableCollector<T> extends Collector<T> {\n",
      "<add> void retract(T record);\n",
      "<add> }\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "if print_for_debug:\n",
    "    for v in range(3):\n",
    "        print(valid_dataset['input_ids'][v])\n",
    "        print(valid_dataset['label'][v])\n",
    "        #print(valid_dataset['attention_mask'][v])\n",
    "        print(tokenizer.decode(valid_dataset['input_ids'][v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:51.216126700Z",
     "start_time": "2023-06-10T14:21:51.160413100Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './models/{}/{}'.format(data_name,model_name_suffix),\n",
    "    num_train_epochs = epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size= batch_size,\n",
    "    save_total_limit = 2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model ='auc',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    eval_steps=4,\n",
    "    disable_tqdm = False,\n",
    "    warmup_steps=warmpup_steps,\n",
    "    logging_steps = 4,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = False,\n",
    "    logging_dir= './models/{}/{}/logs/'.format(data_name,model_name_suffix),\n",
    "    dataloader_num_workers = 0,\n",
    "    max_steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:54.960560300Z",
     "start_time": "2023-06-10T14:21:54.946561200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers.optimization import Adafactor\n",
    "\n",
    "if optim == 'adamw':\n",
    "    opt = torch.optim.AdamW(model.parameters(),lr=init_lr,betas=(0.9, 0.999), eps=adam_eps, weight_decay=weight_decay)\n",
    "elif optim == 'adafactor':\n",
    "    opt = Adafactor(model.parameters(), lr=init_lr, relative_step=False, warmup_init=False)\n",
    "scheduling_types = ['warmpup_anneal', 'warmup','constant']\n",
    "scheduling_type = scheduling_types[1]\n",
    "\n",
    "if scheduling_type == scheduling_types[0]:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=opt,\n",
    "        max_lr=init_lr,\n",
    "        pct_start=training_args.warmup_steps / training_args.max_steps,\n",
    "        anneal_strategy=\"linear\",\n",
    "        total_steps=training_args.max_steps\n",
    "    )\n",
    "elif scheduling_type == scheduling_types[1]:\n",
    "    lr_scheduler = transformers.get_constant_schedule_with_warmup(opt,training_args.warmup_steps)\n",
    "else:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(opt,lambda epoch: init_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "# Login with your authentication key\n",
    "\n",
    "wandb.login()\n",
    "training_hyper_params = {\n",
    "    \"model_name\": model_name_suffix,\n",
    "    \"optimizer\": optim,\n",
    "    \"base_lr\": init_lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"warmpup_factor\":warmpup_factor,\n",
    "    \"warmpup_steps\": warmpup_steps,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "    \"seq_len\": max_commit_code_length,\n",
    "    \"epochs\": epochs,\n",
    "    \"include_commit_msg\":include_message,\n",
    "    \"trained_encoder_layers\":trained_encoder_layers if not use_lora else -1,\n",
    "    \"dataset_version\":version\n",
    "}\n",
    "wandb.init(project=data_name,name='{}/{}'.format(data_name,model_name_suffix),config=training_hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:23:01.891802400Z",
     "start_time": "2023-06-10T14:23:00.817961400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adam_opt = AdamW(model.parameters(),lr=5e-5,betas=[0.9,0.999],weight_decay=0.01)\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset.with_format(\"torch\"),\n",
    "        eval_dataset =valid_dataset.with_format(\"torch\"),\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        optimizers = (opt,lr_scheduler)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:31:14.490328700Z",
     "start_time": "2023-06-10T14:23:04.072872900Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"One Epoch total steps: {}\".format(train_steps / epochs))\n",
    "train_res = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/apache_jit/codebert512_msg_base/checkpoint-7050\n"
     ]
    }
   ],
   "source": [
    "if print_for_debug:\n",
    "    print(trainer.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='941' max='941' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [941/941 01:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6573278903961182, 'eval_accuracy': 0.7102046239702365, 'eval_f1': 0.5420953180768423, 'eval_precision': 0.3894419306184012, 'eval_recall': 0.8915745856353591, 'eval_matthews_correlation': 0.4435147704359337, 'eval_auc': 0.7792851539562119, 'eval_runtime': 60.5454, 'eval_samples_per_second': 124.303, 'eval_steps_per_second': 15.542, 'epoch': 10.01}\n"
     ]
    }
   ],
   "source": [
    "testing=True\n",
    "if testing:\n",
    "    test_dataset = test_dataset.map(encode,load_from_cache_file=False, batch_size=batch_size,batched=True, remove_columns=columns_to_remove)  \n",
    "    trainer.model = AutoModelForSequenceClassification.from_pretrained(trainer.state.best_model_checkpoint).to('cuda') #\n",
    "    test_res = trainer.evaluate(eval_dataset=test_dataset.with_format(\"torch\"))\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bfdea147fd3fde812f8377112128e9c479b40cdcf127ad60d7e7ec5b48ee1c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
