{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.696483700Z",
     "start_time": "2023-06-10T12:14:52.391212500Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import transformers, tokenizers, torch, datasets\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.712484700Z",
     "start_time": "2023-06-10T12:14:58.703481800Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers=4.35.2\n",
      "tokenizers=0.15.0\n",
      "torch=2.1.1+cu121\n",
      "datasets=2.14.5\n"
     ]
    }
   ],
   "source": [
    "print('transformers={}'.format(transformers.__version__))\n",
    "print('tokenizers={}'.format(tokenizers.__version__))\n",
    "print('torch={}'.format(torch.__version__))\n",
    "print('datasets={}'.format(datasets.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.786483300Z",
     "start_time": "2023-06-10T12:14:58.720478300Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:15:31.884556300Z",
     "start_time": "2023-06-10T12:15:31.823559900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def defect_percent(df):\n",
    "    return df['label'].sum()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest_versions = ['base','full_change','special_tokens']\n",
    "models_names = ['bilstm','codebert','codereviewer','javabert','codet5p']\n",
    "fine_tuning_techniques = ['full','partial','lora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_message=True\n",
    "include_metrics=False\n",
    "use_lora = False\n",
    "ft_technique = fine_tuning_techniques[1]\n",
    "lsg_attention = True\n",
    "copy_embedding_from_model=True\n",
    "print_for_debug = True\n",
    "max_commit_code_length = 1024\n",
    "vocab_size = 32000 # 16000, 32000, 52000, for custom tokenizer in BiLSTM model only.\n",
    "partial_trained_encoders = 3\n",
    "model_name = models_names[1]\n",
    "dataset_version_name = datatest_versions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_lsg_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "multiple_files = True\n",
    "data_name = 'apache_jit'\n",
    "prefix = '<java> '\n",
    "columns_to_remove = ['id','msg','code','metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:19:55.033495500Z",
     "start_time": "2023-06-10T12:19:43.529014400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"csv\",data_files=f'datasets/{data_name}/train_{dataset_version_name}_shuffled.csv', streaming=True,split=\"train\")\n",
    "valid_dataset = load_dataset(\"csv\",data_files=f'datasets/{data_name}/valid_{dataset_version_name}_balanced.csv',split=\"train\")\n",
    "test_dataset = load_dataset(\"csv\",data_files=f'datasets/{data_name}/test_{dataset_version_name}.csv',split=\"train\")\n",
    "train_df = pd.read_csv(f'datasets/{data_name}/train_{dataset_version_name}_shuffled.csv')\n",
    "valid_df = pd.read_csv(f'datasets/{data_name}/valid_{dataset_version_name}_balanced.csv')\n",
    "test_df = pd.read_csv(f'datasets/{data_name}/test_{dataset_version_name}.csv')\n",
    "train_length = train_df.shape[0]\n",
    "valid_length = valid_df.shape[0]\n",
    "test_length  = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:19:55.070499600Z",
     "start_time": "2023-06-10T12:19:55.027250200Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "      <th>code</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edebb108d0d0477efba81e55b07339755739dd39</td>\n",
       "      <td>0</td>\n",
       "      <td>[FLINK-11721][network] Remove IOMode from Netw...</td>\n",
       "      <td>[['&lt;del&gt; import org.apache.flink.runtime.io.di...</td>\n",
       "      <td>la:0.000, ld:21.000, nf:6.000, nd:5.000, ns:2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fa84c28fc1bfc62fa2e1165e3407fc81b3d09a9</td>\n",
       "      <td>0</td>\n",
       "      <td>[FLINK-8935][tests] Implement MiniClusterClien...</td>\n",
       "      <td>[['&lt;del&gt; throw new UnsupportedOperationExcepti...</td>\n",
       "      <td>la:17.000, ld:1.000, nf:2.000, nd:2.000, ns:2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70952fe92d5be7f7c9407783867d524544cd9fec</td>\n",
       "      <td>1</td>\n",
       "      <td>IGNITE-9870 GridDhtPartitionsFullMessage#prepa...</td>\n",
       "      <td>[['&lt;add&gt; import java.util.zip.Deflater;', '&lt;de...</td>\n",
       "      <td>la:483.000, ld:245.000, nf:10.000, nd:7.000, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca5d8afee8321e0dff063e8404538b132e979739</td>\n",
       "      <td>0</td>\n",
       "      <td>[FLINK-7192] [java] Activate checkstyle flink-...</td>\n",
       "      <td>[['&lt;del&gt; import java.util.ArrayList;', '&lt;del&gt; ...</td>\n",
       "      <td>la:1179.000, ld:1085.000, nf:20.000, nd:1.000,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75469a3b602c26ea81d6fc0a409d39d321195ea4</td>\n",
       "      <td>1</td>\n",
       "      <td>MINOR: Replacing for with foreach loop in stre...</td>\n",
       "      <td>[['&lt;del&gt; for (int i = 0; i &lt; expectedKeys.leng...</td>\n",
       "      <td>la:227.000, ld:226.000, nf:17.000, nd:1.000, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label  \\\n",
       "0  edebb108d0d0477efba81e55b07339755739dd39      0   \n",
       "1  5fa84c28fc1bfc62fa2e1165e3407fc81b3d09a9      0   \n",
       "2  70952fe92d5be7f7c9407783867d524544cd9fec      1   \n",
       "3  ca5d8afee8321e0dff063e8404538b132e979739      0   \n",
       "4  75469a3b602c26ea81d6fc0a409d39d321195ea4      1   \n",
       "\n",
       "                                                 msg  \\\n",
       "0  [FLINK-11721][network] Remove IOMode from Netw...   \n",
       "1  [FLINK-8935][tests] Implement MiniClusterClien...   \n",
       "2  IGNITE-9870 GridDhtPartitionsFullMessage#prepa...   \n",
       "3  [FLINK-7192] [java] Activate checkstyle flink-...   \n",
       "4  MINOR: Replacing for with foreach loop in stre...   \n",
       "\n",
       "                                                code  \\\n",
       "0  [['<del> import org.apache.flink.runtime.io.di...   \n",
       "1  [['<del> throw new UnsupportedOperationExcepti...   \n",
       "2  [['<add> import java.util.zip.Deflater;', '<de...   \n",
       "3  [['<del> import java.util.ArrayList;', '<del> ...   \n",
       "4  [['<del> for (int i = 0; i < expectedKeys.leng...   \n",
       "\n",
       "                                             metrics  \n",
       "0  la:0.000, ld:21.000, nf:6.000, nd:5.000, ns:2....  \n",
       "1  la:17.000, ld:1.000, nf:2.000, nd:2.000, ns:2....  \n",
       "2  la:483.000, ld:245.000, nf:10.000, nd:7.000, n...  \n",
       "3  la:1179.000, ld:1085.000, nf:20.000, nd:1.000,...  \n",
       "4  la:227.000, ld:226.000, nf:17.000, nd:1.000, n...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:32.352337400Z",
     "start_time": "2023-06-10T14:21:32.340333Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name == 'bilstm':\n",
    "    model_checkpoint = 'microsoft/codereviewer'\n",
    "elif model_name == 'codebert':\n",
    "    model_checkpoint = 'microsoft/codebert-base'\n",
    "elif model_name == 'javabert':\n",
    "    model_checkpoint = 'CAUKiel/JavaBERT'\n",
    "elif model_name == 'codereviewer':\n",
    "    model_checkpoint = 'microsoft/codereviewer'\n",
    "else:\n",
    "    model_checkpoint = 'Salesforce/codet5p-220m'\n",
    "if lsg_attention:\n",
    "    if os.path.exists(\"models/{}_lsg_{}\".format(model_name,max_commit_code_length)):\n",
    "        model_checkpoint = \"models/{}_lsg_{}\".format(model_name,max_commit_code_length)\n",
    "    else:\n",
    "        create_lsg_model = True\n",
    "model_name_suffix = model_name + '_{}{}{}{}{}_{}'.format(max_commit_code_length,'_msg' if include_message else '','_mtc' if include_metrics else '', '_lsg' if lsg_attention else '', '_lora' if use_lora else '',dataset_version_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'javabert':\n",
    "    cls_token = '[CLS]'\n",
    "    sep_token = '[SEP]'\n",
    "    msg_token = '<msg>'\n",
    "    metrics_token = '[CLS]'\n",
    "    code_change_token = '[CLS]'\n",
    "else:\n",
    "    cls_token = '<s>'\n",
    "    sep_token = '</s>'\n",
    "    msg_token = '<msg>'\n",
    "    metrics_token = '<s>'\n",
    "    code_change_token = '<s>'\n",
    "if dataset_version_name == 'special_tokens':\n",
    "    added_token = '<added>'\n",
    "    removed_token = '<removed>'\n",
    "else:\n",
    "    added_token = '<add>'\n",
    "    removed_token = '<del>'\n",
    "prefix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tokens_to_tokenizer(tokenizer):\n",
    "    if dataset_version_name == 'special_tokens':\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[added_token, removed_token,'<STR>','<NUM>']})\n",
    "    if include_message:\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[cls_token, sep_token,'<pad>', '<unk>',added_token, removed_token,msg_token]})\n",
    "    else:\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens':[cls_token, sep_token,'<pad>', '<unk>',added_token, removed_token]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\junior_team\\miniconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:755: FutureWarning: The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\junior_team\\miniconda3\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\junior_team\\miniconda3\\lib\\site-packages\\transformers\\configuration_utils.py:486: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "c:\\Users\\junior_team\\miniconda3\\lib\\site-packages\\transformers\\modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing LSGRobertaForSequenceClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing LSGRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LSGRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LSGRobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.bias', 'embeddings.global_embeddings.weight', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\junior_team\\miniconda3\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if create_lsg_model:\n",
    "    from lsg_converter import LSGConverter\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    converter = LSGConverter(max_sequence_length=max_commit_code_length)\n",
    "    if model_name == 'javabert':\n",
    "        architecture = 'BertForSequenceClassification'\n",
    "    elif model_name == 'codebert':\n",
    "        architecture = 'RobertaForSequenceClassification'\n",
    "    else:\n",
    "        print('Error! LSG Attention not supported for T5 models at the moment. (CodeReviewer and CodeT5+)')\n",
    "        exit()\n",
    "    model, tokenizer = converter.convert_from_pretrained(model_checkpoint,dropout=0.2,hidden_dropout_prob=0.2,num_labels=2,architecture=architecture)\n",
    "    add_tokens_to_tokenizer(tokenizer)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    save_path = 'models/{}_lsg_{}'.format(model_name,max_commit_code_length)\n",
    "    model_checkpoint = save_path\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T13:09:11.104765600Z",
     "start_time": "2023-06-10T13:09:10.300734300Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from bi_lstm import BiLSTM\n",
    "if model_name == 'bilstm':\n",
    "    if copy_embedding_from_model:\n",
    "        tokenizer = AutoTokenizer.from_pretrained( model_checkpoint)\n",
    "    else:\n",
    "        from transformers import RobertaTokenizerFast\n",
    "        tokenizer_name = '{}_{}_bpe'.format(data_name,vocab_size)\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained('./BPE_tokenizer/{}'.format(tokenizer_name),max_len=max_commit_code_length)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained( model_checkpoint)\n",
    "add_tokens_to_tokenizer(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T13:09:48.182646700Z",
     "start_time": "2023-06-10T13:09:48.135006100Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50268\n"
     ]
    }
   ],
   "source": [
    "if print_for_debug:\n",
    "    print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:14:58.787490400Z",
     "start_time": "2023-06-10T12:14:58.741490600Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_empty(seq):\n",
    "    return list(filter(lambda s: s != None and s != '',seq))\n",
    "\n",
    "\n",
    "def join_commit_codes_sep(commit,commit_start=' <NFILE> ',file_sep=' <NFILE> ',line_sep=' <NLINE> '):\n",
    "    if type(commit) == str:\n",
    "        commit = eval(commit)\n",
    "    #return commit_start + file_sep.join(remove_empty([line_sep.join([correct_token(line.split(' ')[0]) +' ' + ' '.join(line.split(' ')[1:]) for line in file]) for file in commit]))\n",
    "    return commit_start + file_sep.join(remove_empty([line_sep.join(file) for file in commit]))\n",
    "\n",
    "def join_commit_codes(commit):\n",
    "    return join_commit_codes_sep(commit,prefix ,f' {sep_token} ','\\n')\n",
    "    #return join_commit_codes_sep(commit,cls_token+' ',f' {sep_token} ',' ')\n",
    "def join_file_lines(file):\n",
    "    if type(file) != list:\n",
    "        file = eval(file)\n",
    "    return prefix +  '\\n'.join(file)\n",
    "\n",
    "def empty_join_commit_codes(commit):\n",
    "    return join_commit_codes_sep(commit,'','')\n",
    "def join_lines(lines,commit_start=' <NFILE> ',line_sep=' <NLINE> '):\n",
    "    return commit_start + line_sep.join(lines)\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "def join_commit_msg_and_code(msg,code):\n",
    "    if msg is None:\n",
    "        msg = ''\n",
    "    if code is None:\n",
    "        code = ''\n",
    "    return msg_token + ' ' + msg.split('\\n')[0] + ' ' + code_change_token + ' ' + join_commit_codes_sep(code ,'',f' {sep_token} ','\\n')\n",
    "def join_commit_msg_metrics_code(msg,mtc,code):\n",
    "    if msg is None:\n",
    "        msg = ''\n",
    "    if code is None:\n",
    "        code = ''\n",
    "    if mtc is None:\n",
    "        mtc = ''\n",
    "    return msg_token + ' ' + msg.split('\\n')[0] + '\\n' + metrics_token + ' ' + mtc + '\\n' + code_change_token + ' ' + join_commit_codes_sep(code ,'',f' {sep_token} ','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:20:03.435005200Z",
     "start_time": "2023-06-10T12:20:03.394801900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode(batch):\n",
    "    if multiple_files:\n",
    "        if include_message:\n",
    "            if include_metrics:\n",
    "                inputs = tokenizer(list(map(join_commit_msg_metrics_code,batch['msg'],batch['metrics'],batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "            else:\n",
    "                inputs = tokenizer(list(map(join_commit_msg_and_code,batch['msg'],batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "        elif include_metrics:\n",
    "            inputs = tokenizer(list(map(join_commit_msg_and_code,batch['metrics'],batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "        else:\n",
    "            inputs = tokenizer(list(map(join_commit_codes,batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "    else:    \n",
    "        inputs = tokenizer(list(map(join_file_lines,batch['code'])),truncation=\"longest_first\",max_length=max_commit_code_length)\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:37.146079600Z",
     "start_time": "2023-06-10T14:21:37.126280Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer,max_length=max_commit_code_length,padding='longest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model classes and initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T12:20:27.676150600Z",
     "start_time": "2023-06-10T12:20:27.652146Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T13:58:32.229044800Z",
     "start_time": "2023-06-10T13:58:30.381801400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel,AutoModelForSequenceClassification, AutoConfig\n",
    "if model_name == 'bilstm':\n",
    "    model = BiLSTM(len(tokenizer),embed_size=768,hidden_size=64,lstm_layers=4,dropout=0.2,padding_id=tokenizer.pad_token_id)\n",
    "    if copy_embedding_from_model:\n",
    "        copy_from_model = AutoModel.from_pretrained(model_checkpoint)\n",
    "        with torch.no_grad():\n",
    "            model.embedding.weight.copy_(copy_from_model.encoder.embed_tokens.weight)\n",
    "            model.embedding.require_grad = False\n",
    "else:\n",
    "    config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "    config.hidden_dropout_prob = 0.2\n",
    "    config.dropout = 0.2\n",
    "    config.num_labels=2\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,config=config)\n",
    "\n",
    "    #change embedding layer size to match tokenizer vocabulary size (Because we added new tokens to the tokenizer):\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'codebert_lsg_1024'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50268, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(1026, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.2, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if print_for_debug:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ft_technique == 'lora':\n",
    "    from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.SEQ_CLS, inference_mode=False, r=16, lora_alpha=16, lora_dropout=0.1, bias=\"all\"\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "    model.print_trainable_parameters()\n",
    "elif ft_technique == 'partial':\n",
    "    # freeze encoder layers except the last 2 layers\n",
    "    modules = []\n",
    "    trained_encoder_layers = partial_trained_encoders\n",
    "    if model_name == 'codebert':\n",
    "        modules = [model.roberta.embeddings, *model.roberta.encoder.layer[:-trained_encoder_layers]]\n",
    "    elif model_name == 'javabert':\n",
    "        modules = [model.bert.embeddings, *model.bert.encoder.layer[:-trained_encoder_layers]]\n",
    "    elif model_name == 'codereviewer' or model_name == 'codet5p':\n",
    "        modules = [model.shared, *model.encoder.block[:-trained_encoder_layers]]\n",
    "    for module in modules:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21855746\n",
      "125042690\n"
     ]
    }
   ],
   "source": [
    "def param_count(model,trainable_only=True):\n",
    "    return sum([p.numel()for p in model.parameters() if p.requires_grad or not trainable_only])\n",
    "if print_for_debug:\n",
    "    print(param_count(model))\n",
    "    print(param_count(model,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:03:52.745412600Z",
     "start_time": "2023-06-10T14:03:52.715422800Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "def roc_auc(preds,target):\n",
    "    roc_auc_score(target, preds)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    _predictions = p.predictions\n",
    "    _labels = p.label_ids\n",
    "    _predictions = np.argmax(_predictions, axis=-1)\n",
    "    vals = {}\n",
    "    vals['accuracy'] = accuracy_score(_labels, _predictions)\n",
    "    vals['f1'] = f1_score(_labels, _predictions)\n",
    "    vals['precision'] = precision_score(_labels, _predictions)\n",
    "    vals['recall'] = recall_score(_labels, _predictions)\n",
    "    vals['matthews_correlation'] = matthews_corrcoef(_labels, _predictions)\n",
    "    vals['auc'] = roc_auc_score(_labels, _predictions.reshape(-1,1))\n",
    "    return  vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:05:59.514455600Z",
     "start_time": "2023-06-10T14:05:59.501453Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers.optimization import AdamW\n",
    "from transformers import Trainer,get_linear_schedule_with_warmup\n",
    "from math import ceil\n",
    "init_lr,head_lr = 5e-4 ,1e-4\n",
    "adam_eps = 1e-6\n",
    "weight_decay = 0.01\n",
    "epochs=10\n",
    "batch_size = 16\n",
    "gradient_accumulation_steps = 4\n",
    "batch_steps = int(train_length/(batch_size*gradient_accumulation_steps))\n",
    "#rem_steps = train_length%(batch_size*gradient_accumulation_steps)\n",
    "rem_steps = ceil((train_length%(batch_size*gradient_accumulation_steps)) / batch_size)\n",
    "train_steps = (epochs) * (batch_steps + rem_steps)\n",
    "warmpup_factor = 0.25\n",
    "warmpup_steps = int(train_steps*warmpup_factor)\n",
    "optim = 'adafactor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:04:34.950969100Z",
     "start_time": "2023-06-10T14:03:54.867449100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa23d30459fc4542864da99c85fb5a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6940 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(encode, batch_size=batch_size,batched=True, remove_columns=columns_to_remove)\n",
    "valid_dataset = valid_dataset.map(encode, batch_size=batch_size,batched=True, remove_columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 50266, 646, 7613, 23617, 12, 21598, 2146, 46386, 34728, 742, 27336, 38, 3765, 4636, 31, 3658, 46291, 1437, 0, 1437, 50267, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 1020, 4, 47340, 4, 118, 16187, 6988, 4, 100, 3765, 260, 6988, 131, 50118, 50267, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 1020, 4, 47340, 4, 118, 16187, 6988, 4, 100, 3765, 260, 6988, 4, 100, 3765, 4636, 131, 50118, 50267, 940, 507, 38, 3765, 260, 6988, 4, 100, 3765, 4636, 6814, 100, 3765, 4636, 131, 50118, 50267, 38, 3765, 260, 6988, 4, 100, 3765, 4636, 4, 21134, 6905, 6, 50118, 50267, 38, 3765, 4636, 6814, 100, 3765, 4636, 6, 50118, 50267, 42, 4, 43234, 100, 3765, 4636, 5457, 6814, 100, 3765, 4636, 131, 50118, 50267, 285, 38, 3765, 4636, 120, 48398, 100, 3765, 4636, 43048, 25522, 50118, 50267, 671, 6814, 100, 3765, 4636, 131, 50118, 50267, 35524, 50118, 1437, 2, 1437, 50267, 1546, 46291, 49602, 4, 1020, 47062, 49196, 50118, 1437, 2, 1437, 50267, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 90, 281, 1071, 1178, 3204, 35853, 4, 18811, 46498, 41101, 44854, 131, 50118, 50267, 77, 1640, 34728, 46291, 4, 6460, 48398, 100, 3765, 4636, 43048, 322, 13040, 42555, 1640, 100, 3765, 260, 6988, 4, 100, 3765, 4636, 4, 21134, 6905, 4397, 50118, 1437, 2, 1437, 50267, 77, 1640, 34728, 4, 6460, 48398, 100, 3765, 4636, 43048, 322, 13040, 42555, 1640, 100, 3765, 260, 6988, 4, 100, 3765, 4636, 4, 21134, 6905, 4397, 50118, 50267, 77, 1640, 34728, 4, 6460, 48398, 100, 3765, 4636, 43048, 322, 13040, 42555, 1640, 100, 3765, 260, 6988, 4, 100, 3765, 4636, 4, 21134, 6905, 4397, 50118, 50267, 77, 1640, 34728, 46291, 4, 6460, 48398, 100, 3765, 4636, 43048, 322, 13040, 42555, 1640, 100, 3765, 260, 6988, 4, 100, 3765, 4636, 4, 21134, 6905, 4397, 50118, 1437, 2, 1437, 50267, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 1020, 4, 47340, 4, 118, 16187, 6988, 4, 100, 3765, 260, 6988, 4, 100, 3765, 4636, 131, 50118, 50267, 38, 3765, 4636, 4, 21134, 6905, 6, 50118, 1437, 2, 1437, 50267, 77, 1640, 34728, 4, 6460, 48398, 100, 3765, 4636, 43048, 322, 13040, 42555, 1640, 100, 3765, 260, 6988, 4, 100, 3765, 4636, 4, 21134, 6905, 4397, 50118, 1437, 50117, 50117, 14746, 1640, 34728, 4, 6460, 47744, 44879, 26402, 11632, 5260, 43048, 322, 13040, 42555, 1640, 45025, 44879, 26402, 11632, 5260, 4397, 2]\n",
      "0\n",
      "<s><msg> [FLINK-11721][network] Remove IOMode from NetworkEnvironment <s> <del> import org.apache.flink.runtime.io.disk.iomanager.IOManager;\n",
      "<del> import org.apache.flink.runtime.io.disk.iomanager.IOManager.IOMode;\n",
      "<del> private final IOManager.IOMode defaultIOMode;\n",
      "<del> IOManager.IOMode.SYNC,\n",
      "<del> IOMode defaultIOMode,\n",
      "<del> this.defaultIOMode = defaultIOMode;\n",
      "<del> public IOMode getDefaultIOMode() {\n",
      "<del> return defaultIOMode;\n",
      "<del> }\n",
      " </s> <del> networkEnvironmentConfiguration.ioMode(),\n",
      " </s> <del> import org.apache.flink.runtime.taskexecutor.GlobalAggregateManager;\n",
      "<del> when(networkEnvironment.getDefaultIOMode()).thenReturn(IOManager.IOMode.SYNC);\n",
      " </s> <del> when(network.getDefaultIOMode()).thenReturn(IOManager.IOMode.SYNC);\n",
      "<del> when(network.getDefaultIOMode()).thenReturn(IOManager.IOMode.SYNC);\n",
      "<del> when(networkEnvironment.getDefaultIOMode()).thenReturn(IOManager.IOMode.SYNC);\n",
      " </s> <del> import org.apache.flink.runtime.io.disk.iomanager.IOManager.IOMode;\n",
      "<del> IOMode.SYNC,\n",
      " </s> <del> when(network.getDefaultIOMode()).thenReturn(IOManager.IOMode.SYNC);\n",
      " \t\twhen(network.getTaskEventDispatcher()).thenReturn(taskEventDispatcher);</s>\n",
      "[0, 50266, 646, 7613, 23617, 12, 5046, 2022, 46386, 47173, 742, 42400, 14912, 11428, 10504, 47952, 10431, 8458, 863, 14247, 1437, 0, 1437, 50267, 3211, 92, 1890, 29799, 35360, 48847, 46469, 44824, 11428, 10504, 47952, 473, 45, 648, 323, 42, 2513, 72, 4397, 50118, 50265, 671, 2510, 3908, 44119, 27814, 1506, 1640, 32081, 11428, 10504, 38304, 8458, 863, 14247, 6, 1768, 46891, 35853, 4397, 50118, 1437, 2, 1437, 50265, 6595, 31118, 4, 48530, 4, 4825, 4291, 4, 49600, 4, 38557, 4, 43128, 47731, 42394, 131, 50118, 50265, 6595, 46900, 4, 32843, 4, 8656, 4, 44252, 994, 131, 50118, 50265, 285, 4556, 8293, 14595, 37577, 41552, 48426, 41552, 43128, 47731, 42394, 44226, 889, 863, 14247, 43048, 25522, 50118, 50265, 860, 25522, 50118, 50265, 671, 120, 26402, 11632, 5260, 37155, 1970, 49123, 16604, 43253, 43128, 45360, 1640, 338, 17426, 49405, 43, 50118, 50265, 479, 13040, 47456, 1640, 41207, 43839, 1315, 4, 6460, 863, 14247, 49123, 8656, 43048, 50118, 50265, 479, 32557, 1640, 45839, 43839, 92, 13576, 47731, 42394, 1640, 45839, 4, 6460, 43128, 28081, 49196, 1254, 4, 6460, 43128, 31723, 49196, 1254, 4, 6460, 47731, 49196, 1254, 4, 6460, 33724, 14699, 43048, 35122, 50118, 50265, 479, 32177, 1640, 44252, 994, 4, 560, 36583, 43048, 48749, 50118, 50265, 35524, 2916, 36, 38660, 27814, 1069, 28017, 48847, 1721, 3870, 45522, 48847, 364, 43, 25522, 50118, 50265, 671, 7543, 41967, 5290, 4, 175, 42711, 48847, 2368, 1640, 50118, 50265, 92, 4150, 4291, 48847, 1640, 50118, 50265, 22, 35299, 45, 22661, 633, 889, 45863, 50118, 50265, 364, 48749, 50118, 50265, 35524, 50118, 50265, 35524, 50118, 1437, 50117, 50117, 50117, 30921, 120, 26402, 11632, 5260, 37155, 1970, 49123, 16604, 43128, 47731, 1640, 30056, 28081, 6, 910, 17426, 49405, 4397, 2]\n",
      "0\n",
      "<s><msg> [FLINK-8935][tests] Implement MiniClusterClient#listJobs <s> <del> throw new UnsupportedOperationException(\"MiniClusterClient does not yet support this operation.\");\n",
      "<add> return guardWithSingleRetry(miniCluster::listJobs, scheduledExecutor);\n",
      " </s> <add> import org.apache.flink.runtime.client.JobStatusMessage;\n",
      "<add> import java.util.stream.Collectors;\n",
      "<add> public CompletableFuture<Collection<JobStatusMessage>> listJobs() {\n",
      "<add> try {\n",
      "<add> return getDispatcherGateway().requestMultipleJobDetails(rpcTimeout)\n",
      "<add>.thenApply(jobs -> jobs.getJobs().stream()\n",
      "<add>.map(details -> new JobStatusMessage(details.getJobId(), details.getJobName(), details.getStatus(), details.getStartTime()))\n",
      "<add>.collect(Collectors.toList()));\n",
      "<add> } catch (LeaderRetrievalException | InterruptedException e) {\n",
      "<add> return FutureUtils.completedExceptionally(\n",
      "<add> new FlinkException(\n",
      "<add> \"Could not retrieve job list.\",\n",
      "<add> e));\n",
      "<add> }\n",
      "<add> }\n",
      " \t\t\treturn getDispatcherGateway().requestJobStatus(jobId, rpcTimeout);</s>\n",
      "[0, 50266, 38171, 12946, 12, 5208, 3083, 22665, 495, 6083, 4741, 8237, 31440, 42394, 10431, 40539, 1322, 40825, 337, 26640, 12980, 1938, 111, 47443, 849, 4540, 541, 4, 1437, 0, 1437, 50265, 6595, 46900, 4, 32843, 4, 39017, 4, 17425, 36600, 131, 50118, 50267, 6595, 31118, 4, 48530, 4, 4932, 1459, 4, 4182, 118, 4, 14210, 43781, 4, 45780, 43781, 12582, 118, 131, 50118, 50265, 6595, 31118, 4, 48530, 4, 4932, 1459, 4, 4182, 118, 4, 14210, 43781, 4, 45780, 43781, 12582, 118, 131, 50118, 50265, 285, 25156, 507, 6979, 211, 7613, 565, 1215, 13548, 45213, 1215, 10370, 27177, 7744, 5457, 7858, 36600, 4, 387, 4923, 1215, 4186, 39857, 131, 50118, 50265, 940, 6979, 1161, 24699, 21791, 38809, 5457, 211, 7613, 565, 1215, 13548, 45213, 1215, 10370, 27177, 7744, 131, 50118, 50265, 285, 6979, 120, 40283, 24699, 21791, 38809, 43048, 25522, 50118, 50265, 671, 1161, 24699, 21791, 38809, 131, 50118, 50265, 35524, 50118, 50265, 285, 13842, 278, 40283, 24699, 21791, 38809, 1640, 2544, 1161, 24699, 21791, 38809, 43, 25522, 50118, 50265, 42, 4, 4135, 24699, 21791, 38809, 5457, 1161, 24699, 21791, 38809, 131, 50118, 50265, 35524, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 2, 1437, 50265, 671, 23796, 131, 50118, 50267, 121, 4, 5016, 1121, 22011, 44682, 1640, 438, 49575, 4, 330, 45738, 48522, 49123, 6460, 36383, 46891, 35853, 32537, 49196, 31232, 347, 11322, 6, 740, 38304, 44847, 1178, 4397, 50118, 50265, 121, 4, 5016, 1121, 22011, 44682, 1640, 438, 49575, 4, 330, 45738, 48522, 49123, 6460, 36383, 46891, 35853, 32537, 49196, 31232, 347, 11322, 6, 326, 43839, 25522, 50118, 50265, 740, 4, 44847, 1178, 1640, 90, 4397, 50118, 50265, 671, 23796, 131, 50118, 50265, 47771, 50118, 50267, 121, 4, 5016, 1121, 22011, 44682, 1640, 438, 49575, 4, 330, 45738, 48522, 49123, 6460, 36383, 46891, 35853, 32537, 49196, 31232, 347, 11322, 6, 740, 38304, 44847, 1178, 4397, 50118, 50265, 121, 4, 5016, 1121, 22011, 44682, 1640, 438, 49575, 4, 330, 45738, 48522, 49123, 6460, 36383, 46891, 35853, 32537, 49196, 31232, 347, 11322, 6, 326, 43839, 25522, 50118, 50265, 740, 4, 44847, 1178, 1640, 90, 4397, 50118, 50265, 671, 23796, 131, 50118, 50265, 47771, 50118, 1437, 2, 1437, 50267, 2776, 48572, 48237, 49191, 41552, 33724, 48572, 39863, 15698, 30283, 33724, 48237, 49191, 50118, 50265, 2776, 48572, 48237, 49191, 41552, 33724, 48572, 39863, 6, 43789, 15698, 30283, 33724, 48237, 49191, 50118, 50267, 30283, 39863, 43839, 3886, 48572, 33724, 1640, 50118, 50267, 30283, 39863, 4, 6460, 48572, 47066, 36423, 368, 49123, 47974, 49602, 49196, 50118, 50267, 30283, 39863, 4, 6460, 48572, 47066, 36423, 368, 49196, 50118, 50267, 30283, 39863, 4, 6460, 9064, 1343, 46034, 347, 41460, 49196, 50118, 50267, 30283, 39863, 4, 6460, 9089, 14035, 14323, 21119, 49196, 50118, 50267, 30283, 39863, 4, 354, 26402, 19875, 4993, 33724, 43048, 50118, 50267, 4839, 50118, 50265, 30283, 39863, 43839, 25522, 50118, 50265, 3886, 48572, 33724, 1640, 50118, 50265, 30283, 39863, 4, 6460, 48572, 47066, 36423, 368, 49123, 47974, 49602, 49196, 50118, 50265, 30283, 39863, 4, 6460, 48572, 47066, 36423, 368, 49196, 50118, 50265, 30283, 39863, 4, 6460, 9064, 1343, 46034, 347, 41460, 49196, 50118, 50265, 30283, 39863, 4, 6460, 9089, 14035, 14323, 21119, 49196, 50118, 50265, 30283, 39863, 4, 354, 26402, 19875, 4993, 33724, 43048, 50118, 50265, 47162, 50118, 50265, 671, 23796, 131, 50118, 50265, 35524, 50118, 50267, 386, 48572, 39863, 43839, 50118, 50265, 386, 48572, 39863, 43839, 25522, 50118, 50265, 671, 23796, 131, 50118, 50267, 4839, 50118, 50265, 47162, 50118, 50265, 671, 23796, 131, 50118, 50265, 35524, 50118, 50265, 671, 23796, 131, 50118, 50267, 30283, 347, 43820, 46640, 43839, 50118, 50265, 30283, 347, 43820, 46640, 43839, 25522, 50118, 50265, 671, 23796, 131, 50118, 50267, 4839, 50118, 50265, 47162, 50118, 50265, 671, 23796, 131, 50118, 50265, 35524, 50118, 50267, 940, 25156, 12332, 2776, 48572, 48237, 49191, 41552, 565, 15698, 25522, 50118, 50265, 940, 25156, 12332, 2776, 48572, 48237, 49191, 41552, 565, 6, 248, 15698, 25522, 50118, 50267, 13842, 3679, 1640, 565, 414, 6, 18762, 1459, 45920, 868, 42909, 41552, 565, 15698, 386, 48572, 35360, 43, 6989, 18762, 1459, 26615, 196, 48847, 131, 50118, 50265, 13842, 3679, 1640, 565, 414, 6, 18762, 1459, 45920, 868, 42909, 41552, 565, 6, 248, 15698, 386, 48572, 35360, 43, 6989, 18762, 1459, 26615, 196, 48847, 131, 50118, 1437, 1437, 1437, 1437, 1437, 1437, 2, 1437, 50267, 671, 131, 50118, 50265, 671, 23796, 131, 50118, 50265, 671, 23796, 131, 50118, 50265, 671, 23796, 131, 50118, 50265, 671, 23796, 131, 50118, 1437, 2, 1437, 50265, 6595, 46900, 4, 32843, 4, 48222, 36583, 131, 50118, 50265, 6595, 46900, 4, 32843, 4, 48426, 131, 50118, 50265, 6595, 46900, 4, 32843, 4, 49981, 131, 50118, 50265, 6595, 31118, 4, 48530, 4, 4932, 1459, 4, 37559, 4, 32843, 4, 32373, 4, 45616, 1459, 45920, 868, 42909, 131, 50118, 50267, 47893, 48992, 1667, 48968, 288, 5457, 23796, 131, 50118, 50267, 47893, 48992, 233, 347, 3999, 4926, 48968, 288, 5457, 23796, 131, 50118, 50267, 47893, 48992, 233, 347, 3999, 4926, 48968, 844, 5457, 23796, 131, 50118, 50267, 47893, 48992, 233, 38657, 33661, 462, 4733, 48968, 288, 5457, 23796, 131, 50118, 50267, 47893, 48992, 1667, 3972, 29806, 20657, 48968, 288, 5457, 23796, 131, 50118, 50267, 47893, 48992, 1667, 104, 7396, 48968, 288, 5457, 23796, 131, 50118, 50267, 47893, 48992, 3335, 4926, 48968, 288, 5457, 23796, 131, 50118, 50265, 6979, 12980, 1809, 574, 41350, 5457, 11945, 4, 29459, 1640, 134, 6, 740, 43820, 4, 330, 45738, 48522, 49123, 43163, 49123, 6460, 36383, 47563, 27262, 45698, 43048, 111, 132, 4397, 50118, 50265, 15937, 41552, 46674, 15698, 8720, 3972, 40825, 1250, 5457, 92, 42719, 36583, 41552, 15698, 47006, 50118, 50265, 114, 48209, 597, 4, 354, 47819, 1640, 41466, 43, 48200, 1667, 48968, 45994, 23796, 43, 50118, 50265, 8720, 3972, 40825, 1250, 4, 4917, 1640, 41466, 4397, 50118, 50265, 114, 36, 7755, 347, 3999, 4926, 49333, 23796, 48200, 27785, 7755, 347, 3999, 4926, 4, 41486, 43048, 48200, 233, 347, 3999, 4926, 48968, 45994, 23796, 43, 50118, 50265, 8720, 3972, 40825, 1250, 4, 4917, 1640, 7755, 347, 3999, 4926, 4397, 50118, 50265, 114, 36, 7755, 347, 3999, 4926, 176, 49333, 23796, 48200, 27785, 7755, 347, 3999, 4926, 176, 4, 41486, 43048, 48200, 233, 347, 3999, 4926, 48968, 176, 45994, 23796, 43, 50118, 50265, 8720, 3972, 40825, 1250, 2]\n",
      "1\n",
      "<s><msg> IGNITE-9870 GridDhtPartitionsFullMessage#prepareMarshal compression parallelization - Fixes #5330. <s> <add> import java.util.zip.Deflater;\n",
      "<del> import org.apache.ignite.spi.encryption.EncryptionSpi;\n",
      "<add> import org.apache.ignite.spi.encryption.EncryptionSpi;\n",
      "<add> public static final int DFLT_NETWORK_COMPRESSION = Deflater.BEST_SPEED;\n",
      "<add> private int netCompressionLevel = DFLT_NETWORK_COMPRESSION;\n",
      "<add> public int getNetworkCompressionLevel() {\n",
      "<add> return netCompressionLevel;\n",
      "<add> }\n",
      "<add> public void setNetworkCompressionLevel(int netCompressionLevel) {\n",
      "<add> this.netCompressionLevel = netCompressionLevel;\n",
      "<add> }\n",
      "      </s> <add> return null;\n",
      "<del> U.doInParallel(cctx.kernalContext().getSystemExecutorService(), affinityCaches, c::applyx);\n",
      "<add> U.doInParallel(cctx.kernalContext().getSystemExecutorService(), affinityCaches, t -> {\n",
      "<add> c.applyx(t);\n",
      "<add> return null;\n",
      "<add> });\n",
      "<del> U.doInParallel(cctx.kernalContext().getSystemExecutorService(), affinityCaches, c::applyx);\n",
      "<add> U.doInParallel(cctx.kernalContext().getSystemExecutorService(), affinityCaches, t -> {\n",
      "<add> c.applyx(t);\n",
      "<add> return null;\n",
      "<add> });\n",
      " </s> <del> StartCacheFailHandler<StartCacheInfo> cacheStartFailHandler\n",
      "<add> StartCacheFailHandler<StartCacheInfo, Void> cacheStartFailHandler\n",
      "<del> cacheInfo -> prepareCacheStart(\n",
      "<del> cacheInfo.getCacheDescriptor().cacheConfiguration(),\n",
      "<del> cacheInfo.getCacheDescriptor(),\n",
      "<del> cacheInfo.getReqNearCfg(),\n",
      "<del> cacheInfo.getExchangeTopVer(),\n",
      "<del> cacheInfo.isDisabledAfterStart()\n",
      "<del> )\n",
      "<add> cacheInfo -> {\n",
      "<add> prepareCacheStart(\n",
      "<add> cacheInfo.getCacheDescriptor().cacheConfiguration(),\n",
      "<add> cacheInfo.getCacheDescriptor(),\n",
      "<add> cacheInfo.getReqNearCfg(),\n",
      "<add> cacheInfo.getExchangeTopVer(),\n",
      "<add> cacheInfo.isDisabledAfterStart()\n",
      "<add> );\n",
      "<add> return null;\n",
      "<add> }\n",
      "<del> startCacheInfo ->\n",
      "<add> startCacheInfo -> {\n",
      "<add> return null;\n",
      "<del> )\n",
      "<add> );\n",
      "<add> return null;\n",
      "<add> }\n",
      "<add> return null;\n",
      "<del> cacheCtxEntry ->\n",
      "<add> cacheCtxEntry -> {\n",
      "<add> return null;\n",
      "<del> )\n",
      "<add> );\n",
      "<add> return null;\n",
      "<add> }\n",
      "<del> private static interface StartCacheFailHandler<T> {\n",
      "<add> private static interface StartCacheFailHandler<T, R> {\n",
      "<del> void handle(T data, IgniteThrowableConsumer<T> startCacheOperation) throws IgniteCheckedException;\n",
      "<add> void handle(T data, IgniteThrowableConsumer<T, R> startCacheOperation) throws IgniteCheckedException;\n",
      "      </s> <del> return;\n",
      "<add> return null;\n",
      "<add> return null;\n",
      "<add> return null;\n",
      "<add> return null;\n",
      " </s> <add> import java.util.ArrayList;\n",
      "<add> import java.util.Collection;\n",
      "<add> import java.util.Iterator;\n",
      "<add> import org.apache.ignite.internal.util.lang.IgniteThrowableConsumer;\n",
      "<del> byte[] partsBytes0 = null;\n",
      "<del> byte[] partCntrsBytes0 = null;\n",
      "<del> byte[] partCntrsBytes20 = null;\n",
      "<del> byte[] partHistSuppliersBytes0 = null;\n",
      "<del> byte[] partsToReloadBytes0 = null;\n",
      "<del> byte[] partsSizesBytes0 = null;\n",
      "<del> byte[] errsBytes0 = null;\n",
      "<add> int parallelismLvl = Math.max(1, ctx.kernalContext().config().getSystemThreadPoolSize() - 2);\n",
      "<add> Collection<Object> objectsToMarshall = new ArrayList<>();\n",
      "<add> if (!F.isEmpty(parts) && partsBytes == null)\n",
      "<add> objectsToMarshall.add(parts);\n",
      "<add> if (partCntrs!= null &&!partCntrs.empty() && partCntrsBytes == null)\n",
      "<add> objectsToMarshall.add(partCntrs);\n",
      "<add> if (partCntrs2!= null &&!partCntrs2.empty() && partCntrsBytes2 == null)\n",
      "<add> objectsToMarshall</s>\n"
     ]
    }
   ],
   "source": [
    "if print_for_debug:\n",
    "    for v in range(3):\n",
    "        print(valid_dataset['input_ids'][v])\n",
    "        print(valid_dataset['label'][v])\n",
    "        #print(valid_dataset['attention_mask'][v])\n",
    "        print(tokenizer.decode(valid_dataset['input_ids'][v]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:51.216126700Z",
     "start_time": "2023-06-10T14:21:51.160413100Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './models/{}/{}'.format(data_name,model_name_suffix),\n",
    "    num_train_epochs = epochs,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size= batch_size,\n",
    "    save_total_limit = 2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model ='auc',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    eval_steps=4,\n",
    "    disable_tqdm = False,\n",
    "    warmup_steps=warmpup_steps,\n",
    "    logging_steps = 4,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=\"wandb\",\n",
    "    fp16 = False,\n",
    "    logging_dir= './models/{}/{}/logs/'.format(data_name,model_name_suffix),\n",
    "    dataloader_num_workers = 0,\n",
    "    max_steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:21:54.960560300Z",
     "start_time": "2023-06-10T14:21:54.946561200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers.optimization import Adafactor\n",
    "\n",
    "if optim == 'adamw':\n",
    "    opt = torch.optim.AdamW(model.parameters(),lr=init_lr,betas=(0.9, 0.999), eps=adam_eps, weight_decay=weight_decay)\n",
    "elif optim == 'adafactor':\n",
    "    opt = Adafactor(model.parameters(), lr=init_lr, relative_step=False, warmup_init=False)\n",
    "scheduling_types = ['warmpup_anneal', 'warmup','constant']\n",
    "scheduling_type = scheduling_types[1]\n",
    "\n",
    "if scheduling_type == scheduling_types[0]:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=opt,\n",
    "        max_lr=init_lr,\n",
    "        pct_start=training_args.warmup_steps / training_args.max_steps,\n",
    "        anneal_strategy=\"linear\",\n",
    "        total_steps=training_args.max_steps\n",
    "    )\n",
    "elif scheduling_type == scheduling_types[1]:\n",
    "    lr_scheduler = transformers.get_constant_schedule_with_warmup(opt,training_args.warmup_steps)\n",
    "else:\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(opt,lambda epoch: init_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myaseralosh\u001b[0m (\u001b[33mjit_defect\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>e:\\Yaser Research\\JIT-SDP-CodePTMs\\wandb\\run-20240105_205359-lzpdx5y4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jit_defect/apache_jit/runs/lzpdx5y4' target=\"_blank\">apache_jit/codebert_1024_msg_lsg_base</a></strong> to <a href='https://wandb.ai/jit_defect/apache_jit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jit_defect/apache_jit' target=\"_blank\">https://wandb.ai/jit_defect/apache_jit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jit_defect/apache_jit/runs/lzpdx5y4' target=\"_blank\">https://wandb.ai/jit_defect/apache_jit/runs/lzpdx5y4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/jit_defect/apache_jit/runs/lzpdx5y4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x21bf752b490>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Login with your authentication key\n",
    "\n",
    "wandb.login()\n",
    "training_hyper_params = {\n",
    "    \"model_name\": model_name_suffix,\n",
    "    \"optimizer\": optim,\n",
    "    \"base_lr\": init_lr,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"warmpup_factor\":warmpup_factor,\n",
    "    \"warmpup_steps\": warmpup_steps,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "    \"seq_len\": max_commit_code_length,\n",
    "    \"epochs\": epochs,\n",
    "    \"include_commit_msg\":include_message,\n",
    "    \"trained_encoder_layers\":trained_encoder_layers if not use_lora else -1,\n",
    "    \"dataset_version\":dataset_version_name\n",
    "}\n",
    "wandb.init(project=data_name,name='{}/{}'.format(data_name,model_name_suffix),config=training_hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T14:23:01.891802400Z",
     "start_time": "2023-06-10T14:23:00.817961400Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adam_opt = AdamW(model.parameters(),lr=5e-5,betas=[0.9,0.999],weight_decay=0.01)\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset.with_format(\"torch\"),\n",
    "        eval_dataset =valid_dataset.with_format(\"torch\"),\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        optimizers = (opt,lr_scheduler)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T15:31:14.490328700Z",
     "start_time": "2023-06-10T14:23:04.072872900Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Epoch total steps: 703.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e0f0157bef4566979aca7f7c478378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7030 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7254, 'learning_rate': 1.1383039271485487e-06, 'epoch': 0.0}\n",
      "{'loss': 0.7015, 'learning_rate': 2.2766078542970975e-06, 'epoch': 0.0}\n",
      "{'loss': 0.7041, 'learning_rate': 3.414911781445646e-06, 'epoch': 0.0}\n",
      "{'loss': 0.6959, 'learning_rate': 4.553215708594195e-06, 'epoch': 0.0}\n",
      "{'loss': 0.6945, 'learning_rate': 5.6915196357427435e-06, 'epoch': 0.0}\n",
      "{'loss': 0.7155, 'learning_rate': 6.829823562891292e-06, 'epoch': 0.0}\n",
      "{'loss': 0.7147, 'learning_rate': 7.96812749003984e-06, 'epoch': 0.0}\n",
      "{'loss': 0.7102, 'learning_rate': 9.10643141718839e-06, 'epoch': 0.0}\n",
      "{'loss': 0.7168, 'learning_rate': 1.024473534433694e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7011, 'learning_rate': 1.1383039271485487e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7114, 'learning_rate': 1.2521343198634035e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7101, 'learning_rate': 1.3659647125782584e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7114, 'learning_rate': 1.4797951052931132e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7173, 'learning_rate': 1.593625498007968e-05, 'epoch': 0.01}\n",
      "{'loss': 0.6905, 'learning_rate': 1.707455890722823e-05, 'epoch': 0.01}\n",
      "{'loss': 0.6965, 'learning_rate': 1.821286283437678e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7066, 'learning_rate': 1.935116676152533e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7015, 'learning_rate': 2.048947068867388e-05, 'epoch': 0.01}\n",
      "{'loss': 0.711, 'learning_rate': 2.1627774615822425e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7135, 'learning_rate': 2.2766078542970974e-05, 'epoch': 0.01}\n",
      "{'loss': 0.6843, 'learning_rate': 2.3904382470119523e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7031, 'learning_rate': 2.504268639726807e-05, 'epoch': 0.01}\n",
      "{'loss': 0.6947, 'learning_rate': 2.618099032441662e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7073, 'learning_rate': 2.7319294251565168e-05, 'epoch': 0.01}\n",
      "{'loss': 0.6961, 'learning_rate': 2.8457598178713718e-05, 'epoch': 0.01}\n",
      "{'loss': 0.6902, 'learning_rate': 2.9595902105862264e-05, 'epoch': 0.01}\n",
      "{'loss': 0.7013, 'learning_rate': 3.0734206033010816e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6927, 'learning_rate': 3.187250996015936e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6758, 'learning_rate': 3.3010813887307915e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6774, 'learning_rate': 3.414911781445646e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6865, 'learning_rate': 3.528742174160501e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6916, 'learning_rate': 3.642572566875356e-05, 'epoch': 0.02}\n",
      "{'loss': 0.7054, 'learning_rate': 3.7564029595902106e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6774, 'learning_rate': 3.870233352305066e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6805, 'learning_rate': 3.9840637450199205e-05, 'epoch': 0.02}\n",
      "{'loss': 0.673, 'learning_rate': 4.097894137734776e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6792, 'learning_rate': 4.2117245304496303e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6927, 'learning_rate': 4.325554923164485e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6971, 'learning_rate': 4.43938531587934e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6944, 'learning_rate': 4.553215708594195e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6841, 'learning_rate': 4.66704610130905e-05, 'epoch': 0.02}\n",
      "{'loss': 0.693, 'learning_rate': 4.780876494023905e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6818, 'learning_rate': 4.89470688673876e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6691, 'learning_rate': 5.008537279453614e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6812, 'learning_rate': 5.1223676721684685e-05, 'epoch': 0.03}\n",
      "{'loss': 0.683, 'learning_rate': 5.236198064883324e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6659, 'learning_rate': 5.3500284575981784e-05, 'epoch': 0.03}\n",
      "{'loss': 0.693, 'learning_rate': 5.4638588503130336e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6898, 'learning_rate': 5.577689243027888e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6814, 'learning_rate': 5.6915196357427435e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6784, 'learning_rate': 5.805350028457598e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6738, 'learning_rate': 5.919180421172453e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6588, 'learning_rate': 6.033010813887308e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6865, 'learning_rate': 6.146841206602163e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6784, 'learning_rate': 6.260671599317018e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6644, 'learning_rate': 6.374501992031872e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6695, 'learning_rate': 6.488332384746727e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6841, 'learning_rate': 6.602162777461583e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6845, 'learning_rate': 6.715993170176438e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6967, 'learning_rate': 6.829823562891292e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6584, 'learning_rate': 6.943653955606147e-05, 'epoch': 0.03}\n",
      "{'loss': 0.6704, 'learning_rate': 7.057484348321001e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6676, 'learning_rate': 7.171314741035857e-05, 'epoch': 0.04}\n",
      "{'loss': 0.654, 'learning_rate': 7.285145133750712e-05, 'epoch': 0.04}\n",
      "{'loss': 0.67, 'learning_rate': 7.398975526465567e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6589, 'learning_rate': 7.512805919180421e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6187, 'learning_rate': 7.626636311895276e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6578, 'learning_rate': 7.740466704610132e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6393, 'learning_rate': 7.854297097324986e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6596, 'learning_rate': 7.968127490039841e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6658, 'learning_rate': 8.081957882754696e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6282, 'learning_rate': 8.195788275469551e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6607, 'learning_rate': 8.309618668184406e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6534, 'learning_rate': 8.423449060899261e-05, 'epoch': 0.04}\n",
      "{'loss': 0.636, 'learning_rate': 8.537279453614115e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6378, 'learning_rate': 8.65110984632897e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6433, 'learning_rate': 8.764940239043826e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6154, 'learning_rate': 8.87877063175868e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6414, 'learning_rate': 8.992601024473535e-05, 'epoch': 0.04}\n",
      "{'loss': 0.6606, 'learning_rate': 9.10643141718839e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6448, 'learning_rate': 9.220261809903244e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6402, 'learning_rate': 9.3340922026181e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6274, 'learning_rate': 9.447922595332955e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6118, 'learning_rate': 9.56175298804781e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6224, 'learning_rate': 9.675583380762664e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6307, 'learning_rate': 9.78941377347752e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6302, 'learning_rate': 9.903244166192375e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6045, 'learning_rate': 0.00010017074558907228, 'epoch': 0.05}\n",
      "{'loss': 0.6037, 'learning_rate': 0.00010130904951622082, 'epoch': 0.05}\n",
      "{'loss': 0.6673, 'learning_rate': 0.00010244735344336937, 'epoch': 0.05}\n",
      "{'loss': 0.6491, 'learning_rate': 0.00010358565737051793, 'epoch': 0.05}\n",
      "{'loss': 0.6312, 'learning_rate': 0.00010472396129766648, 'epoch': 0.05}\n",
      "{'loss': 0.6227, 'learning_rate': 0.00010586226522481502, 'epoch': 0.05}\n",
      "{'loss': 0.5901, 'learning_rate': 0.00010700056915196357, 'epoch': 0.05}\n",
      "{'loss': 0.6554, 'learning_rate': 0.00010813887307911211, 'epoch': 0.05}\n",
      "{'loss': 0.6384, 'learning_rate': 0.00010927717700626067, 'epoch': 0.05}\n",
      "{'loss': 0.6026, 'learning_rate': 0.00011041548093340922, 'epoch': 0.06}\n",
      "{'loss': 0.6159, 'learning_rate': 0.00011155378486055776, 'epoch': 0.06}\n",
      "{'loss': 0.5925, 'learning_rate': 0.00011269208878770631, 'epoch': 0.06}\n",
      "{'loss': 0.6316, 'learning_rate': 0.00011383039271485487, 'epoch': 0.06}\n",
      "{'loss': 0.613, 'learning_rate': 0.00011496869664200342, 'epoch': 0.06}\n",
      "{'loss': 0.5775, 'learning_rate': 0.00011610700056915196, 'epoch': 0.06}\n",
      "{'loss': 0.6356, 'learning_rate': 0.00011724530449630051, 'epoch': 0.06}\n",
      "{'loss': 0.6135, 'learning_rate': 0.00011838360842344905, 'epoch': 0.06}\n",
      "{'loss': 0.5711, 'learning_rate': 0.00011952191235059761, 'epoch': 0.06}\n",
      "{'loss': 0.6212, 'learning_rate': 0.00012066021627774616, 'epoch': 0.06}\n",
      "{'loss': 0.5787, 'learning_rate': 0.0001217985202048947, 'epoch': 0.06}\n",
      "{'loss': 0.6221, 'learning_rate': 0.00012293682413204327, 'epoch': 0.06}\n",
      "{'loss': 0.6416, 'learning_rate': 0.00012407512805919183, 'epoch': 0.06}\n",
      "{'loss': 0.6079, 'learning_rate': 0.00012521343198634036, 'epoch': 0.06}\n",
      "{'loss': 0.5608, 'learning_rate': 0.0001263517359134889, 'epoch': 0.06}\n",
      "{'loss': 0.61, 'learning_rate': 0.00012749003984063745, 'epoch': 0.06}\n",
      "{'loss': 0.6011, 'learning_rate': 0.000128628343767786, 'epoch': 0.06}\n",
      "{'loss': 0.6043, 'learning_rate': 0.00012976664769493454, 'epoch': 0.06}\n",
      "{'loss': 0.5812, 'learning_rate': 0.0001309049516220831, 'epoch': 0.07}\n",
      "{'loss': 0.6201, 'learning_rate': 0.00013204325554923166, 'epoch': 0.07}\n",
      "{'loss': 0.6214, 'learning_rate': 0.0001331815594763802, 'epoch': 0.07}\n",
      "{'loss': 0.5974, 'learning_rate': 0.00013431986340352875, 'epoch': 0.07}\n",
      "{'loss': 0.5919, 'learning_rate': 0.00013545816733067729, 'epoch': 0.07}\n",
      "{'loss': 0.5923, 'learning_rate': 0.00013659647125782584, 'epoch': 0.07}\n",
      "{'loss': 0.588, 'learning_rate': 0.0001377347751849744, 'epoch': 0.07}\n",
      "{'loss': 0.5886, 'learning_rate': 0.00013887307911212294, 'epoch': 0.07}\n",
      "{'loss': 0.5992, 'learning_rate': 0.0001400113830392715, 'epoch': 0.07}\n",
      "{'loss': 0.5564, 'learning_rate': 0.00014114968696642003, 'epoch': 0.07}\n",
      "{'loss': 0.5805, 'learning_rate': 0.0001422879908935686, 'epoch': 0.07}\n",
      "{'loss': 0.5802, 'learning_rate': 0.00014342629482071715, 'epoch': 0.07}\n",
      "{'loss': 0.5472, 'learning_rate': 0.00014456459874786568, 'epoch': 0.07}\n",
      "{'loss': 0.6051, 'learning_rate': 0.00014570290267501424, 'epoch': 0.07}\n",
      "{'loss': 0.5572, 'learning_rate': 0.00014684120660216277, 'epoch': 0.07}\n",
      "{'loss': 0.5858, 'learning_rate': 0.00014797951052931133, 'epoch': 0.07}\n",
      "{'loss': 0.632, 'learning_rate': 0.0001491178144564599, 'epoch': 0.07}\n",
      "{'loss': 0.5499, 'learning_rate': 0.00015025611838360842, 'epoch': 0.08}\n",
      "{'loss': 0.598, 'learning_rate': 0.00015139442231075698, 'epoch': 0.08}\n",
      "{'loss': 0.6305, 'learning_rate': 0.00015253272623790552, 'epoch': 0.08}\n",
      "{'loss': 0.5926, 'learning_rate': 0.00015367103016505408, 'epoch': 0.08}\n",
      "{'loss': 0.5922, 'learning_rate': 0.00015480933409220263, 'epoch': 0.08}\n",
      "{'loss': 0.6452, 'learning_rate': 0.00015594763801935117, 'epoch': 0.08}\n",
      "{'loss': 0.6125, 'learning_rate': 0.00015708594194649973, 'epoch': 0.08}\n",
      "{'loss': 0.6037, 'learning_rate': 0.00015822424587364826, 'epoch': 0.08}\n",
      "{'loss': 0.5883, 'learning_rate': 0.00015936254980079682, 'epoch': 0.08}\n",
      "{'loss': 0.6017, 'learning_rate': 0.00016050085372794538, 'epoch': 0.08}\n",
      "{'loss': 0.5786, 'learning_rate': 0.0001616391576550939, 'epoch': 0.08}\n",
      "{'loss': 0.626, 'learning_rate': 0.00016277746158224247, 'epoch': 0.08}\n",
      "{'loss': 0.5894, 'learning_rate': 0.00016391576550939103, 'epoch': 0.08}\n",
      "{'loss': 0.5998, 'learning_rate': 0.00016505406943653956, 'epoch': 0.08}\n",
      "{'loss': 0.6056, 'learning_rate': 0.00016619237336368812, 'epoch': 0.08}\n",
      "{'loss': 0.558, 'learning_rate': 0.00016733067729083665, 'epoch': 0.08}\n",
      "{'loss': 0.5577, 'learning_rate': 0.00016846898121798521, 'epoch': 0.08}\n",
      "{'loss': 0.5798, 'learning_rate': 0.00016960728514513377, 'epoch': 0.08}\n",
      "{'loss': 0.6176, 'learning_rate': 0.0001707455890722823, 'epoch': 0.09}\n",
      "{'loss': 0.6289, 'learning_rate': 0.00017188389299943087, 'epoch': 0.09}\n",
      "{'loss': 0.6217, 'learning_rate': 0.0001730221969265794, 'epoch': 0.09}\n",
      "{'loss': 0.6064, 'learning_rate': 0.00017416050085372796, 'epoch': 0.09}\n",
      "{'loss': 0.6126, 'learning_rate': 0.00017529880478087652, 'epoch': 0.09}\n",
      "{'loss': 0.5872, 'learning_rate': 0.00017643710870802505, 'epoch': 0.09}\n",
      "{'loss': 0.6137, 'learning_rate': 0.0001775754126351736, 'epoch': 0.09}\n",
      "{'loss': 0.584, 'learning_rate': 0.00017871371656232214, 'epoch': 0.09}\n",
      "{'loss': 0.5832, 'learning_rate': 0.0001798520204894707, 'epoch': 0.09}\n",
      "{'loss': 0.5576, 'learning_rate': 0.00018099032441661926, 'epoch': 0.09}\n",
      "{'loss': 0.6165, 'learning_rate': 0.0001821286283437678, 'epoch': 0.09}\n",
      "{'loss': 0.5862, 'learning_rate': 0.00018326693227091635, 'epoch': 0.09}\n",
      "{'loss': 0.5523, 'learning_rate': 0.00018440523619806488, 'epoch': 0.09}\n",
      "{'loss': 0.5872, 'learning_rate': 0.00018554354012521344, 'epoch': 0.09}\n",
      "{'loss': 0.573, 'learning_rate': 0.000186681844052362, 'epoch': 0.09}\n",
      "{'loss': 0.5871, 'learning_rate': 0.00018782014797951054, 'epoch': 0.09}\n",
      "{'loss': 0.5596, 'learning_rate': 0.0001889584519066591, 'epoch': 0.09}\n",
      "{'loss': 0.6125, 'learning_rate': 0.00019009675583380766, 'epoch': 0.1}\n",
      "{'loss': 0.5662, 'learning_rate': 0.0001912350597609562, 'epoch': 0.1}\n",
      "{'loss': 0.581, 'learning_rate': 0.00019237336368810475, 'epoch': 0.1}\n",
      "{'loss': 0.5926, 'learning_rate': 0.00019351166761525328, 'epoch': 0.1}\n",
      "{'loss': 0.5732, 'learning_rate': 0.00019464997154240184, 'epoch': 0.1}\n",
      "{'loss': 0.5588, 'learning_rate': 0.0001957882754695504, 'epoch': 0.1}\n",
      "{'loss': 0.5771, 'learning_rate': 0.00019692657939669893, 'epoch': 0.1}\n",
      "{'loss': 0.6448, 'learning_rate': 0.0001980648833238475, 'epoch': 0.1}\n",
      "{'loss': 0.5792, 'learning_rate': 0.000199203187250996, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7fc2c38ed640e1a2e3b538ff7f8c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6067043542861938, 'eval_accuracy': 0.6786743515850144, 'eval_f1': 0.7078092243186582, 'eval_precision': 0.6489668428640077, 'eval_recall': 0.7783861671469741, 'eval_matthews_correlation': 0.36467376976184873, 'eval_auc': 0.6786743515850144, 'eval_runtime': 141.3914, 'eval_samples_per_second': 49.084, 'eval_steps_per_second': 3.069, 'epoch': 0.1}\n",
      "{'loss': 0.5465, 'learning_rate': 0.00020034149117814456, 'epoch': 1.0}\n",
      "{'loss': 0.5472, 'learning_rate': 0.00020147979510529312, 'epoch': 1.0}\n",
      "{'loss': 0.6219, 'learning_rate': 0.00020261809903244165, 'epoch': 1.0}\n",
      "{'loss': 0.5944, 'learning_rate': 0.0002037564029595902, 'epoch': 1.0}\n",
      "{'loss': 0.5817, 'learning_rate': 0.00020489470688673874, 'epoch': 1.0}\n",
      "{'loss': 0.6119, 'learning_rate': 0.0002060330108138873, 'epoch': 1.0}\n",
      "{'loss': 0.5674, 'learning_rate': 0.00020717131474103586, 'epoch': 1.0}\n",
      "{'loss': 0.5711, 'learning_rate': 0.0002083096186681844, 'epoch': 1.0}\n",
      "{'loss': 0.5735, 'learning_rate': 0.00020944792259533295, 'epoch': 1.01}\n",
      "{'loss': 0.6318, 'learning_rate': 0.00021058622652248148, 'epoch': 1.01}\n",
      "{'loss': 0.6453, 'learning_rate': 0.00021172453044963004, 'epoch': 1.01}\n",
      "{'loss': 0.596, 'learning_rate': 0.0002128628343767786, 'epoch': 1.01}\n",
      "{'loss': 0.5926, 'learning_rate': 0.00021400113830392713, 'epoch': 1.01}\n",
      "{'loss': 0.5982, 'learning_rate': 0.0002151394422310757, 'epoch': 1.01}\n",
      "{'loss': 0.5772, 'learning_rate': 0.00021627774615822423, 'epoch': 1.01}\n",
      "{'loss': 0.5873, 'learning_rate': 0.00021741605008537279, 'epoch': 1.01}\n",
      "{'loss': 0.596, 'learning_rate': 0.00021855435401252135, 'epoch': 1.01}\n",
      "{'loss': 0.5849, 'learning_rate': 0.00021969265793966988, 'epoch': 1.01}\n",
      "{'loss': 0.5528, 'learning_rate': 0.00022083096186681844, 'epoch': 1.01}\n",
      "{'loss': 0.5519, 'learning_rate': 0.000221969265793967, 'epoch': 1.01}\n",
      "{'loss': 0.5392, 'learning_rate': 0.00022310756972111553, 'epoch': 1.01}\n",
      "{'loss': 0.5998, 'learning_rate': 0.0002242458736482641, 'epoch': 1.01}\n",
      "{'loss': 0.5274, 'learning_rate': 0.00022538417757541262, 'epoch': 1.01}\n",
      "{'loss': 0.5494, 'learning_rate': 0.00022652248150256118, 'epoch': 1.01}\n",
      "{'loss': 0.6002, 'learning_rate': 0.00022766078542970974, 'epoch': 1.01}\n",
      "{'loss': 0.5557, 'learning_rate': 0.00022879908935685827, 'epoch': 1.01}\n",
      "{'loss': 0.5941, 'learning_rate': 0.00022993739328400683, 'epoch': 1.02}\n",
      "{'loss': 0.5241, 'learning_rate': 0.00023107569721115537, 'epoch': 1.02}\n",
      "{'loss': 0.532, 'learning_rate': 0.00023221400113830392, 'epoch': 1.02}\n",
      "{'loss': 0.5511, 'learning_rate': 0.00023335230506545248, 'epoch': 1.02}\n",
      "{'loss': 0.5486, 'learning_rate': 0.00023449060899260102, 'epoch': 1.02}\n",
      "{'loss': 0.6371, 'learning_rate': 0.00023562891291974958, 'epoch': 1.02}\n",
      "{'loss': 0.6095, 'learning_rate': 0.0002367672168468981, 'epoch': 1.02}\n",
      "{'loss': 0.5806, 'learning_rate': 0.00023790552077404667, 'epoch': 1.02}\n",
      "{'loss': 0.535, 'learning_rate': 0.00023904382470119523, 'epoch': 1.02}\n",
      "{'loss': 0.6234, 'learning_rate': 0.00024018212862834376, 'epoch': 1.02}\n",
      "{'loss': 0.6097, 'learning_rate': 0.00024132043255549232, 'epoch': 1.02}\n",
      "{'loss': 0.5603, 'learning_rate': 0.00024245873648264085, 'epoch': 1.02}\n",
      "{'loss': 0.5991, 'learning_rate': 0.0002435970404097894, 'epoch': 1.02}\n",
      "{'loss': 0.58, 'learning_rate': 0.00024473534433693797, 'epoch': 1.02}\n",
      "{'loss': 0.6279, 'learning_rate': 0.00024587364826408653, 'epoch': 1.02}\n",
      "{'loss': 0.6037, 'learning_rate': 0.0002470119521912351, 'epoch': 1.02}\n",
      "{'loss': 0.546, 'learning_rate': 0.00024815025611838365, 'epoch': 1.02}\n",
      "{'loss': 0.6078, 'learning_rate': 0.00024928856004553216, 'epoch': 1.02}\n",
      "{'loss': 0.5012, 'learning_rate': 0.0002504268639726807, 'epoch': 1.03}\n",
      "{'loss': 0.5654, 'learning_rate': 0.0002515651678998293, 'epoch': 1.03}\n",
      "{'loss': 0.5593, 'learning_rate': 0.0002527034718269778, 'epoch': 1.03}\n",
      "{'loss': 0.582, 'learning_rate': 0.0002538417757541264, 'epoch': 1.03}\n",
      "{'loss': 0.6227, 'learning_rate': 0.0002549800796812749, 'epoch': 1.03}\n",
      "{'loss': 0.6004, 'learning_rate': 0.00025611838360842346, 'epoch': 1.03}\n",
      "{'loss': 0.579, 'learning_rate': 0.000257256687535572, 'epoch': 1.03}\n",
      "{'loss': 0.582, 'learning_rate': 0.0002583949914627206, 'epoch': 1.03}\n",
      "{'loss': 0.5338, 'learning_rate': 0.0002595332953898691, 'epoch': 1.03}\n",
      "{'loss': 0.5583, 'learning_rate': 0.0002606715993170177, 'epoch': 1.03}\n",
      "{'loss': 0.5651, 'learning_rate': 0.0002618099032441662, 'epoch': 1.03}\n",
      "{'loss': 0.5661, 'learning_rate': 0.00026294820717131476, 'epoch': 1.03}\n",
      "{'loss': 0.6408, 'learning_rate': 0.0002640865110984633, 'epoch': 1.03}\n",
      "{'loss': 0.5914, 'learning_rate': 0.0002652248150256119, 'epoch': 1.03}\n",
      "{'loss': 0.563, 'learning_rate': 0.0002663631189527604, 'epoch': 1.03}\n",
      "{'loss': 0.6079, 'learning_rate': 0.0002675014228799089, 'epoch': 1.03}\n",
      "{'loss': 0.5342, 'learning_rate': 0.0002686397268070575, 'epoch': 1.03}\n",
      "{'loss': 0.5688, 'learning_rate': 0.000269778030734206, 'epoch': 1.04}\n",
      "{'loss': 0.6377, 'learning_rate': 0.00027091633466135457, 'epoch': 1.04}\n",
      "{'loss': 0.5907, 'learning_rate': 0.00027205463858850313, 'epoch': 1.04}\n",
      "{'loss': 0.567, 'learning_rate': 0.0002731929425156517, 'epoch': 1.04}\n",
      "{'loss': 0.5488, 'learning_rate': 0.0002743312464428002, 'epoch': 1.04}\n",
      "{'loss': 0.5384, 'learning_rate': 0.0002754695503699488, 'epoch': 1.04}\n",
      "{'loss': 0.6346, 'learning_rate': 0.0002766078542970973, 'epoch': 1.04}\n",
      "{'loss': 0.5844, 'learning_rate': 0.0002777461582242459, 'epoch': 1.04}\n",
      "{'loss': 0.5869, 'learning_rate': 0.0002788844621513944, 'epoch': 1.04}\n",
      "{'loss': 0.5607, 'learning_rate': 0.000280022766078543, 'epoch': 1.04}\n",
      "{'loss': 0.5707, 'learning_rate': 0.0002811610700056915, 'epoch': 1.04}\n",
      "{'loss': 0.5529, 'learning_rate': 0.00028229937393284006, 'epoch': 1.04}\n",
      "{'loss': 0.5357, 'learning_rate': 0.0002834376778599886, 'epoch': 1.04}\n",
      "{'loss': 0.5323, 'learning_rate': 0.0002845759817871372, 'epoch': 1.04}\n",
      "{'loss': 0.5597, 'learning_rate': 0.0002857142857142857, 'epoch': 1.04}\n",
      "{'loss': 0.5647, 'learning_rate': 0.0002868525896414343, 'epoch': 1.04}\n",
      "{'loss': 0.5695, 'learning_rate': 0.0002879908935685828, 'epoch': 1.04}\n",
      "{'loss': 0.5537, 'learning_rate': 0.00028912919749573136, 'epoch': 1.04}\n",
      "{'loss': 0.577, 'learning_rate': 0.0002902675014228799, 'epoch': 1.05}\n",
      "{'loss': 0.6109, 'learning_rate': 0.0002914058053500285, 'epoch': 1.05}\n",
      "{'loss': 0.546, 'learning_rate': 0.000292544109277177, 'epoch': 1.05}\n",
      "{'loss': 0.5633, 'learning_rate': 0.00029368241320432554, 'epoch': 1.05}\n",
      "{'loss': 0.5164, 'learning_rate': 0.0002948207171314741, 'epoch': 1.05}\n",
      "{'loss': 0.5563, 'learning_rate': 0.00029595902105862266, 'epoch': 1.05}\n",
      "{'loss': 0.5504, 'learning_rate': 0.00029709732498577117, 'epoch': 1.05}\n",
      "{'loss': 0.5497, 'learning_rate': 0.0002982356289129198, 'epoch': 1.05}\n",
      "{'loss': 0.5341, 'learning_rate': 0.0002993739328400683, 'epoch': 1.05}\n",
      "{'loss': 0.5475, 'learning_rate': 0.00030051223676721685, 'epoch': 1.05}\n",
      "{'loss': 0.6215, 'learning_rate': 0.0003016505406943654, 'epoch': 1.05}\n",
      "{'loss': 0.5506, 'learning_rate': 0.00030278884462151397, 'epoch': 1.05}\n",
      "{'loss': 0.58, 'learning_rate': 0.00030392714854866247, 'epoch': 1.05}\n",
      "{'loss': 0.5541, 'learning_rate': 0.00030506545247581103, 'epoch': 1.05}\n",
      "{'loss': 0.5657, 'learning_rate': 0.0003062037564029596, 'epoch': 1.05}\n",
      "{'loss': 0.5555, 'learning_rate': 0.00030734206033010815, 'epoch': 1.05}\n",
      "{'loss': 0.5814, 'learning_rate': 0.00030848036425725666, 'epoch': 1.05}\n",
      "{'loss': 0.5786, 'learning_rate': 0.00030961866818440527, 'epoch': 1.06}\n",
      "{'loss': 0.528, 'learning_rate': 0.0003107569721115538, 'epoch': 1.06}\n",
      "{'loss': 0.5396, 'learning_rate': 0.00031189527603870233, 'epoch': 1.06}\n",
      "{'loss': 0.6009, 'learning_rate': 0.0003130335799658509, 'epoch': 1.06}\n",
      "{'loss': 0.5408, 'learning_rate': 0.00031417188389299945, 'epoch': 1.06}\n",
      "{'loss': 0.5312, 'learning_rate': 0.00031531018782014796, 'epoch': 1.06}\n",
      "{'loss': 0.5506, 'learning_rate': 0.0003164484917472965, 'epoch': 1.06}\n",
      "{'loss': 0.5917, 'learning_rate': 0.0003175867956744451, 'epoch': 1.06}\n",
      "{'loss': 0.5224, 'learning_rate': 0.00031872509960159364, 'epoch': 1.06}\n",
      "{'loss': 0.5763, 'learning_rate': 0.00031986340352874214, 'epoch': 1.06}\n",
      "{'loss': 0.5122, 'learning_rate': 0.00032100170745589076, 'epoch': 1.06}\n",
      "{'loss': 0.5632, 'learning_rate': 0.00032214001138303926, 'epoch': 1.06}\n",
      "{'loss': 0.6276, 'learning_rate': 0.0003232783153101878, 'epoch': 1.06}\n",
      "{'loss': 0.5267, 'learning_rate': 0.0003244166192373364, 'epoch': 1.06}\n",
      "{'loss': 0.5564, 'learning_rate': 0.00032555492316448494, 'epoch': 1.06}\n",
      "{'loss': 0.574, 'learning_rate': 0.00032669322709163345, 'epoch': 1.06}\n",
      "{'loss': 0.5342, 'learning_rate': 0.00032783153101878206, 'epoch': 1.06}\n",
      "{'loss': 0.524, 'learning_rate': 0.00032896983494593056, 'epoch': 1.06}\n",
      "{'loss': 0.5621, 'learning_rate': 0.0003301081388730791, 'epoch': 1.07}\n",
      "{'loss': 0.4925, 'learning_rate': 0.00033124644280022763, 'epoch': 1.07}\n",
      "{'loss': 0.561, 'learning_rate': 0.00033238474672737624, 'epoch': 1.07}\n",
      "{'loss': 0.5836, 'learning_rate': 0.00033352305065452475, 'epoch': 1.07}\n",
      "{'loss': 0.5279, 'learning_rate': 0.0003346613545816733, 'epoch': 1.07}\n",
      "{'loss': 0.5605, 'learning_rate': 0.00033579965850882187, 'epoch': 1.07}\n",
      "{'loss': 0.5636, 'learning_rate': 0.00033693796243597043, 'epoch': 1.07}\n",
      "{'loss': 0.5362, 'learning_rate': 0.00033807626636311893, 'epoch': 1.07}\n",
      "{'loss': 0.5668, 'learning_rate': 0.00033921457029026755, 'epoch': 1.07}\n",
      "{'loss': 0.5733, 'learning_rate': 0.00034035287421741605, 'epoch': 1.07}\n",
      "{'loss': 0.5532, 'learning_rate': 0.0003414911781445646, 'epoch': 1.07}\n",
      "{'loss': 0.5548, 'learning_rate': 0.0003426294820717131, 'epoch': 1.07}\n",
      "{'loss': 0.5161, 'learning_rate': 0.00034376778599886173, 'epoch': 1.07}\n",
      "{'loss': 0.5969, 'learning_rate': 0.00034490608992601024, 'epoch': 1.07}\n",
      "{'loss': 0.5233, 'learning_rate': 0.0003460443938531588, 'epoch': 1.07}\n",
      "{'loss': 0.5319, 'learning_rate': 0.00034718269778030735, 'epoch': 1.07}\n",
      "{'loss': 0.6037, 'learning_rate': 0.0003483210017074559, 'epoch': 1.07}\n",
      "{'loss': 0.4914, 'learning_rate': 0.0003494593056346044, 'epoch': 1.07}\n",
      "{'loss': 0.571, 'learning_rate': 0.00035059760956175303, 'epoch': 1.08}\n",
      "{'loss': 0.5351, 'learning_rate': 0.00035173591348890154, 'epoch': 1.08}\n",
      "{'loss': 0.5685, 'learning_rate': 0.0003528742174160501, 'epoch': 1.08}\n",
      "{'loss': 0.5499, 'learning_rate': 0.00035401252134319866, 'epoch': 1.08}\n",
      "{'loss': 0.5478, 'learning_rate': 0.0003551508252703472, 'epoch': 1.08}\n",
      "{'loss': 0.6144, 'learning_rate': 0.0003562891291974957, 'epoch': 1.08}\n",
      "{'loss': 0.5588, 'learning_rate': 0.0003574274331246443, 'epoch': 1.08}\n",
      "{'loss': 0.5471, 'learning_rate': 0.00035856573705179284, 'epoch': 1.08}\n",
      "{'loss': 0.5674, 'learning_rate': 0.0003597040409789414, 'epoch': 1.08}\n",
      "{'loss': 0.5233, 'learning_rate': 0.0003608423449060899, 'epoch': 1.08}\n",
      "{'loss': 0.5697, 'learning_rate': 0.0003619806488332385, 'epoch': 1.08}\n",
      "{'loss': 0.6048, 'learning_rate': 0.000363118952760387, 'epoch': 1.08}\n",
      "{'loss': 0.5896, 'learning_rate': 0.0003642572566875356, 'epoch': 1.08}\n",
      "{'loss': 0.5893, 'learning_rate': 0.00036539556061468415, 'epoch': 1.08}\n",
      "{'loss': 0.5245, 'learning_rate': 0.0003665338645418327, 'epoch': 1.08}\n",
      "{'loss': 0.492, 'learning_rate': 0.0003676721684689812, 'epoch': 1.08}\n",
      "{'loss': 0.5622, 'learning_rate': 0.00036881047239612977, 'epoch': 1.08}\n",
      "{'loss': 0.533, 'learning_rate': 0.00036994877632327833, 'epoch': 1.09}\n",
      "{'loss': 0.61, 'learning_rate': 0.0003710870802504269, 'epoch': 1.09}\n",
      "{'loss': 0.5605, 'learning_rate': 0.0003722253841775754, 'epoch': 1.09}\n",
      "{'loss': 0.5852, 'learning_rate': 0.000373363688104724, 'epoch': 1.09}\n",
      "{'loss': 0.5556, 'learning_rate': 0.0003745019920318725, 'epoch': 1.09}\n",
      "{'loss': 0.5629, 'learning_rate': 0.00037564029595902107, 'epoch': 1.09}\n",
      "{'loss': 0.6081, 'learning_rate': 0.00037677859988616963, 'epoch': 1.09}\n",
      "{'loss': 0.5195, 'learning_rate': 0.0003779169038133182, 'epoch': 1.09}\n",
      "{'loss': 0.5212, 'learning_rate': 0.0003790552077404667, 'epoch': 1.09}\n",
      "{'loss': 0.5351, 'learning_rate': 0.0003801935116676153, 'epoch': 1.09}\n",
      "{'loss': 0.5418, 'learning_rate': 0.0003813318155947638, 'epoch': 1.09}\n",
      "{'loss': 0.5553, 'learning_rate': 0.0003824701195219124, 'epoch': 1.09}\n",
      "{'loss': 0.5111, 'learning_rate': 0.0003836084234490609, 'epoch': 1.09}\n",
      "{'loss': 0.5339, 'learning_rate': 0.0003847467273762095, 'epoch': 1.09}\n",
      "{'loss': 0.5456, 'learning_rate': 0.000385885031303358, 'epoch': 1.09}\n",
      "{'loss': 0.5402, 'learning_rate': 0.00038702333523050656, 'epoch': 1.09}\n",
      "{'loss': 0.5421, 'learning_rate': 0.0003881616391576551, 'epoch': 1.09}\n",
      "{'loss': 0.5767, 'learning_rate': 0.0003892999430848037, 'epoch': 1.09}\n",
      "{'loss': 0.5282, 'learning_rate': 0.0003904382470119522, 'epoch': 1.1}\n",
      "{'loss': 0.5686, 'learning_rate': 0.0003915765509391008, 'epoch': 1.1}\n",
      "{'loss': 0.5408, 'learning_rate': 0.0003927148548662493, 'epoch': 1.1}\n",
      "{'loss': 0.5217, 'learning_rate': 0.00039385315879339786, 'epoch': 1.1}\n",
      "{'loss': 0.5033, 'learning_rate': 0.00039499146272054637, 'epoch': 1.1}\n",
      "{'loss': 0.5778, 'learning_rate': 0.000396129766647695, 'epoch': 1.1}\n",
      "{'loss': 0.5432, 'learning_rate': 0.0003972680705748435, 'epoch': 1.1}\n",
      "{'loss': 0.5494, 'learning_rate': 0.000398406374501992, 'epoch': 1.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a290bb5507b54ba3bb2b81274d870acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5697055459022522, 'eval_accuracy': 0.7054755043227666, 'eval_f1': 0.7426340972047344, 'eval_precision': 0.6594364937388193, 'eval_recall': 0.8498559077809799, 'eval_matthews_correlation': 0.4292359123529265, 'eval_auc': 0.7054755043227666, 'eval_runtime': 141.1519, 'eval_samples_per_second': 49.167, 'eval_steps_per_second': 3.075, 'epoch': 1.1}\n",
      "{'loss': 0.4916, 'learning_rate': 0.0003995446784291406, 'epoch': 2.0}\n",
      "{'loss': 0.4805, 'learning_rate': 0.0004006829823562891, 'epoch': 2.0}\n",
      "{'loss': 0.6, 'learning_rate': 0.00040182128628343767, 'epoch': 2.0}\n",
      "{'loss': 0.5626, 'learning_rate': 0.00040295959021058623, 'epoch': 2.0}\n",
      "{'loss': 0.5761, 'learning_rate': 0.0004040978941377348, 'epoch': 2.0}\n",
      "{'loss': 0.5667, 'learning_rate': 0.0004052361980648833, 'epoch': 2.0}\n",
      "{'loss': 0.5279, 'learning_rate': 0.0004063745019920319, 'epoch': 2.0}\n",
      "{'loss': 0.5554, 'learning_rate': 0.0004075128059191804, 'epoch': 2.0}\n",
      "{'loss': 0.5589, 'learning_rate': 0.000408651109846329, 'epoch': 2.0}\n",
      "{'loss': 0.5623, 'learning_rate': 0.0004097894137734775, 'epoch': 2.01}\n",
      "{'loss': 0.6089, 'learning_rate': 0.0004109277177006261, 'epoch': 2.01}\n",
      "{'loss': 0.534, 'learning_rate': 0.0004120660216277746, 'epoch': 2.01}\n",
      "{'loss': 0.5281, 'learning_rate': 0.00041320432555492316, 'epoch': 2.01}\n",
      "{'loss': 0.5728, 'learning_rate': 0.0004143426294820717, 'epoch': 2.01}\n",
      "{'loss': 0.5951, 'learning_rate': 0.0004154809334092203, 'epoch': 2.01}\n",
      "{'loss': 0.5663, 'learning_rate': 0.0004166192373363688, 'epoch': 2.01}\n",
      "{'loss': 0.5556, 'learning_rate': 0.0004177575412635174, 'epoch': 2.01}\n",
      "{'loss': 0.5752, 'learning_rate': 0.0004188958451906659, 'epoch': 2.01}\n",
      "{'loss': 0.5198, 'learning_rate': 0.00042003414911781446, 'epoch': 2.01}\n",
      "{'loss': 0.5177, 'learning_rate': 0.00042117245304496297, 'epoch': 2.01}\n",
      "{'loss': 0.4714, 'learning_rate': 0.0004223107569721116, 'epoch': 2.01}\n",
      "{'loss': 0.5258, 'learning_rate': 0.0004234490608992601, 'epoch': 2.01}\n",
      "{'loss': 0.5171, 'learning_rate': 0.00042458736482640865, 'epoch': 2.01}\n",
      "{'loss': 0.5114, 'learning_rate': 0.0004257256687535572, 'epoch': 2.01}\n",
      "{'loss': 0.4946, 'learning_rate': 0.00042686397268070576, 'epoch': 2.01}\n",
      "{'loss': 0.5003, 'learning_rate': 0.00042800227660785427, 'epoch': 2.01}\n",
      "{'loss': 0.5015, 'learning_rate': 0.0004291405805350029, 'epoch': 2.02}\n",
      "{'loss': 0.4698, 'learning_rate': 0.0004302788844621514, 'epoch': 2.02}\n",
      "{'loss': 0.5241, 'learning_rate': 0.00043141718838929995, 'epoch': 2.02}\n",
      "{'loss': 0.4769, 'learning_rate': 0.00043255549231644845, 'epoch': 2.02}\n",
      "{'loss': 0.5073, 'learning_rate': 0.00043369379624359707, 'epoch': 2.02}\n",
      "{'loss': 0.5706, 'learning_rate': 0.00043483210017074557, 'epoch': 2.02}\n",
      "{'loss': 0.5535, 'learning_rate': 0.00043597040409789413, 'epoch': 2.02}\n",
      "{'loss': 0.5329, 'learning_rate': 0.0004371087080250427, 'epoch': 2.02}\n",
      "{'loss': 0.4997, 'learning_rate': 0.00043824701195219125, 'epoch': 2.02}\n",
      "{'loss': 0.5354, 'learning_rate': 0.00043938531587933976, 'epoch': 2.02}\n",
      "{'loss': 0.526, 'learning_rate': 0.00044052361980648837, 'epoch': 2.02}\n",
      "{'loss': 0.5044, 'learning_rate': 0.0004416619237336369, 'epoch': 2.02}\n",
      "{'loss': 0.5742, 'learning_rate': 0.00044280022766078544, 'epoch': 2.02}\n",
      "{'loss': 0.5164, 'learning_rate': 0.000443938531587934, 'epoch': 2.02}\n",
      "{'loss': 0.5593, 'learning_rate': 0.00044507683551508255, 'epoch': 2.02}\n",
      "{'loss': 0.5518, 'learning_rate': 0.00044621513944223106, 'epoch': 2.02}\n",
      "{'loss': 0.5013, 'learning_rate': 0.0004473534433693796, 'epoch': 2.02}\n",
      "{'loss': 0.5114, 'learning_rate': 0.0004484917472965282, 'epoch': 2.02}\n",
      "{'loss': 0.5087, 'learning_rate': 0.00044963005122367674, 'epoch': 2.03}\n",
      "{'loss': 0.4994, 'learning_rate': 0.00045076835515082524, 'epoch': 2.03}\n",
      "{'loss': 0.4964, 'learning_rate': 0.00045190665907797386, 'epoch': 2.03}\n",
      "{'loss': 0.5276, 'learning_rate': 0.00045304496300512236, 'epoch': 2.03}\n",
      "{'loss': 0.5452, 'learning_rate': 0.0004541832669322709, 'epoch': 2.03}\n",
      "{'loss': 0.5693, 'learning_rate': 0.0004553215708594195, 'epoch': 2.03}\n",
      "{'loss': 0.497, 'learning_rate': 0.00045645987478656804, 'epoch': 2.03}\n",
      "{'loss': 0.5428, 'learning_rate': 0.00045759817871371655, 'epoch': 2.03}\n",
      "{'loss': 0.5116, 'learning_rate': 0.0004587364826408651, 'epoch': 2.03}\n",
      "{'loss': 0.4642, 'learning_rate': 0.00045987478656801367, 'epoch': 2.03}\n",
      "{'loss': 0.5104, 'learning_rate': 0.0004610130904951622, 'epoch': 2.03}\n",
      "{'loss': 0.5287, 'learning_rate': 0.00046215139442231073, 'epoch': 2.03}\n",
      "{'loss': 0.5509, 'learning_rate': 0.00046328969834945934, 'epoch': 2.03}\n",
      "{'loss': 0.559, 'learning_rate': 0.00046442800227660785, 'epoch': 2.03}\n",
      "{'loss': 0.5073, 'learning_rate': 0.0004655663062037564, 'epoch': 2.03}\n",
      "{'loss': 0.4891, 'learning_rate': 0.00046670461013090497, 'epoch': 2.03}\n",
      "{'loss': 0.5222, 'learning_rate': 0.00046784291405805353, 'epoch': 2.03}\n",
      "{'loss': 0.4878, 'learning_rate': 0.00046898121798520203, 'epoch': 2.04}\n",
      "{'loss': 0.6007, 'learning_rate': 0.00047011952191235065, 'epoch': 2.04}\n",
      "{'loss': 0.5239, 'learning_rate': 0.00047125782583949915, 'epoch': 2.04}\n",
      "{'loss': 0.4881, 'learning_rate': 0.0004723961297666477, 'epoch': 2.04}\n",
      "{'loss': 0.5085, 'learning_rate': 0.0004735344336937962, 'epoch': 2.04}\n",
      "{'loss': 0.4854, 'learning_rate': 0.00047467273762094483, 'epoch': 2.04}\n",
      "{'loss': 0.5775, 'learning_rate': 0.00047581104154809334, 'epoch': 2.04}\n",
      "{'loss': 0.5316, 'learning_rate': 0.0004769493454752419, 'epoch': 2.04}\n",
      "{'loss': 0.5462, 'learning_rate': 0.00047808764940239046, 'epoch': 2.04}\n",
      "{'loss': 0.5272, 'learning_rate': 0.000479225953329539, 'epoch': 2.04}\n",
      "{'loss': 0.5139, 'learning_rate': 0.0004803642572566875, 'epoch': 2.04}\n",
      "{'loss': 0.4826, 'learning_rate': 0.00048150256118383613, 'epoch': 2.04}\n",
      "{'loss': 0.4885, 'learning_rate': 0.00048264086511098464, 'epoch': 2.04}\n",
      "{'loss': 0.4715, 'learning_rate': 0.0004837791690381332, 'epoch': 2.04}\n",
      "{'loss': 0.4913, 'learning_rate': 0.0004849174729652817, 'epoch': 2.04}\n",
      "{'loss': 0.486, 'learning_rate': 0.0004860557768924303, 'epoch': 2.04}\n",
      "{'loss': 0.5082, 'learning_rate': 0.0004871940808195788, 'epoch': 2.04}\n",
      "{'loss': 0.5192, 'learning_rate': 0.0004883323847467274, 'epoch': 2.04}\n",
      "{'loss': 0.4798, 'learning_rate': 0.0004894706886738759, 'epoch': 2.05}\n",
      "{'loss': 0.5574, 'learning_rate': 0.0004906089926010245, 'epoch': 2.05}\n",
      "{'loss': 0.4762, 'learning_rate': 0.0004917472965281731, 'epoch': 2.05}\n",
      "{'loss': 0.4731, 'learning_rate': 0.0004928856004553216, 'epoch': 2.05}\n",
      "{'loss': 0.4828, 'learning_rate': 0.0004940239043824702, 'epoch': 2.05}\n",
      "{'loss': 0.4759, 'learning_rate': 0.0004951622083096186, 'epoch': 2.05}\n",
      "{'loss': 0.4483, 'learning_rate': 0.0004963005122367673, 'epoch': 2.05}\n",
      "{'loss': 0.4978, 'learning_rate': 0.0004974388161639158, 'epoch': 2.05}\n",
      "{'loss': 0.4962, 'learning_rate': 0.0004985771200910643, 'epoch': 2.05}\n",
      "{'loss': 0.4991, 'learning_rate': 0.0004997154240182129, 'epoch': 2.05}\n",
      "{'loss': 0.5778, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.5003, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.5006, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.4989, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.5286, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.5242, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.5126, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.5374, 'learning_rate': 0.0005, 'epoch': 2.05}\n",
      "{'loss': 0.4857, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4442, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.5276, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.5061, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4366, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4815, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.56, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.479, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.5276, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4597, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.5192, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.5448, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4768, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4766, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4987, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4721, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.4776, 'learning_rate': 0.0005, 'epoch': 2.06}\n",
      "{'loss': 0.499, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4406, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4784, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.5214, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4527, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4923, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.5151, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.525, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4822, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4818, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4914, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.5097, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4488, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.518, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4795, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.5081, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.5105, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4766, 'learning_rate': 0.0005, 'epoch': 2.07}\n",
      "{'loss': 0.4782, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.4654, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5389, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5414, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5429, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5604, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.529, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.4929, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5159, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.4996, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5471, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5272, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5151, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5034, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.4653, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.4685, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.41, 'learning_rate': 0.0005, 'epoch': 2.08}\n",
      "{'loss': 0.5647, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5269, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5007, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5295, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5349, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.442, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5154, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.4243, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.4804, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.472, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5212, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.4991, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5271, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.4227, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5418, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.4977, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.4969, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.5276, 'learning_rate': 0.0005, 'epoch': 2.09}\n",
      "{'loss': 0.4962, 'learning_rate': 0.0005, 'epoch': 2.1}\n",
      "{'loss': 0.4663, 'learning_rate': 0.0005, 'epoch': 2.1}\n",
      "{'loss': 0.4875, 'learning_rate': 0.0005, 'epoch': 2.1}\n",
      "{'loss': 0.4615, 'learning_rate': 0.0005, 'epoch': 2.1}\n",
      "{'loss': 0.4619, 'learning_rate': 0.0005, 'epoch': 2.1}\n",
      "{'loss': 0.4652, 'learning_rate': 0.0005, 'epoch': 2.1}\n",
      "{'loss': 0.4918, 'learning_rate': 0.0005, 'epoch': 2.1}\n",
      "{'loss': 0.5195, 'learning_rate': 0.0005, 'epoch': 2.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5b3fb8095a448ca737f85945dc6ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5322141051292419, 'eval_accuracy': 0.7474063400576368, 'eval_f1': 0.7853031230863441, 'eval_precision': 0.6828541001064963, 'eval_recall': 0.9239193083573487, 'eval_matthews_correlation': 0.5288643881925791, 'eval_auc': 0.747406340057637, 'eval_runtime': 141.308, 'eval_samples_per_second': 49.113, 'eval_steps_per_second': 3.071, 'epoch': 2.1}\n",
      "{'loss': 0.4637, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.4136, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.5086, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.5002, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.4887, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.5516, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.5058, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.5064, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.4648, 'learning_rate': 0.0005, 'epoch': 3.0}\n",
      "{'loss': 0.5588, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.515, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4942, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4517, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4743, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.5425, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.5369, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4685, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.5409, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4968, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4534, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4443, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4353, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4676, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.5022, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4812, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4672, 'learning_rate': 0.0005, 'epoch': 3.01}\n",
      "{'loss': 0.4439, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4525, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4514, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4798, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4804, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4925, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.459, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4615, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4753, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.5117, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4795, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.5005, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4912, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4631, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.5307, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.5105, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4861, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4675, 'learning_rate': 0.0005, 'epoch': 3.02}\n",
      "{'loss': 0.4344, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4702, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.446, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.5023, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4794, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4682, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4493, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4561, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4669, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.3894, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4974, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4643, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.529, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.5399, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4375, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4589, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4875, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.4511, 'learning_rate': 0.0005, 'epoch': 3.03}\n",
      "{'loss': 0.56, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4895, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4803, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4855, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4587, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.5339, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.5252, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.5179, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.5184, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4428, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4918, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.483, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4231, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4885, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4236, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.513, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4417, 'learning_rate': 0.0005, 'epoch': 3.04}\n",
      "{'loss': 0.4273, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.5092, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4696, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.49, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4646, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4684, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4453, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4799, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.464, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.451, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.5513, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.5093, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4772, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4808, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.5156, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.4602, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.5332, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.5251, 'learning_rate': 0.0005, 'epoch': 3.05}\n",
      "{'loss': 0.5244, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4046, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.5138, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4579, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4468, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.3878, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.5755, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.453, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.477, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4833, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4874, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.5177, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4465, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.459, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4409, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4453, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4799, 'learning_rate': 0.0005, 'epoch': 3.06}\n",
      "{'loss': 0.4811, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4146, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4141, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.5008, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4472, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4746, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4415, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4989, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4676, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4296, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.466, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.488, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4351, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.5207, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4986, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4738, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.5225, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4543, 'learning_rate': 0.0005, 'epoch': 3.07}\n",
      "{'loss': 0.4265, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.51, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4615, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.5018, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4743, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.5562, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4937, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4736, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.517, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4526, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.5054, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.5492, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4985, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4869, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4472, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4636, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.3988, 'learning_rate': 0.0005, 'epoch': 3.08}\n",
      "{'loss': 0.4788, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.5084, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4846, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.5101, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4987, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4391, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4971, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4585, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4009, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4545, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.5184, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.455, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4944, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.413, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.5319, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4863, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4817, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.4995, 'learning_rate': 0.0005, 'epoch': 3.09}\n",
      "{'loss': 0.5202, 'learning_rate': 0.0005, 'epoch': 3.1}\n",
      "{'loss': 0.4499, 'learning_rate': 0.0005, 'epoch': 3.1}\n",
      "{'loss': 0.4778, 'learning_rate': 0.0005, 'epoch': 3.1}\n",
      "{'loss': 0.4562, 'learning_rate': 0.0005, 'epoch': 3.1}\n",
      "{'loss': 0.4448, 'learning_rate': 0.0005, 'epoch': 3.1}\n",
      "{'loss': 0.4743, 'learning_rate': 0.0005, 'epoch': 3.1}\n",
      "{'loss': 0.471, 'learning_rate': 0.0005, 'epoch': 3.1}\n",
      "{'loss': 0.5409, 'learning_rate': 0.0005, 'epoch': 3.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56d2e92189d4efdad3cdc7830eecee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48480120301246643, 'eval_accuracy': 0.7753602305475504, 'eval_f1': 0.7852912821925354, 'eval_precision': 0.7520443154840412, 'eval_recall': 0.8216138328530259, 'eval_matthews_correlation': 0.5530921116959865, 'eval_auc': 0.7753602305475504, 'eval_runtime': 141.5785, 'eval_samples_per_second': 49.019, 'eval_steps_per_second': 3.065, 'epoch': 3.1}\n",
      "{'loss': 0.4211, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4402, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4913, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4781, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4771, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4836, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4612, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.5225, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4511, 'learning_rate': 0.0005, 'epoch': 4.0}\n",
      "{'loss': 0.4824, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.542, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4615, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4921, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4349, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.5235, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.5145, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4816, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.507, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4909, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4678, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4463, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.3999, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4664, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4998, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4695, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4439, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4061, 'learning_rate': 0.0005, 'epoch': 4.01}\n",
      "{'loss': 0.4441, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4424, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4762, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4745, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.5024, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4565, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4332, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4709, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.471, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.459, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.5082, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4965, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4461, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4938, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.5334, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4634, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4488, 'learning_rate': 0.0005, 'epoch': 4.02}\n",
      "{'loss': 0.4614, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4577, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4125, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.5106, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4653, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4496, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4739, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4681, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4377, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4322, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4476, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4611, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.5266, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.5001, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4489, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4727, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.4804, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.459, 'learning_rate': 0.0005, 'epoch': 4.03}\n",
      "{'loss': 0.5364, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.514, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4573, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4717, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4338, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4962, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.5393, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.472, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4854, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.511, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4603, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.471, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4012, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4772, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4565, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4678, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4507, 'learning_rate': 0.0005, 'epoch': 4.04}\n",
      "{'loss': 0.4536, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.5095, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4385, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4917, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4638, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4666, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4445, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.3928, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4486, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4636, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.5075, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.5145, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4351, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4644, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.496, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4784, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.4923, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.5331, 'learning_rate': 0.0005, 'epoch': 4.05}\n",
      "{'loss': 0.5063, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4222, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4709, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4747, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4134, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.3688, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.5569, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4568, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4208, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.5283, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4494, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4862, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4375, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.481, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.3869, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.436, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4548, 'learning_rate': 0.0005, 'epoch': 4.06}\n",
      "{'loss': 0.4733, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.3943, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4149, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4999, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4406, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4982, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4198, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.5185, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4545, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4594, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4273, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4671, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.468, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4699, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.5265, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4647, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4916, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.5053, 'learning_rate': 0.0005, 'epoch': 4.07}\n",
      "{'loss': 0.4065, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4828, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4894, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.5037, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4822, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.5065, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4971, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4793, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4873, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4366, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4926, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.5087, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.5304, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4485, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4728, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4431, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4026, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4489, 'learning_rate': 0.0005, 'epoch': 4.08}\n",
      "{'loss': 0.4765, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4732, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.512, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4922, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4427, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4538, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4645, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4555, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4158, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4594, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4493, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4698, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4345, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4791, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4784, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4501, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.5196, 'learning_rate': 0.0005, 'epoch': 4.09}\n",
      "{'loss': 0.4451, 'learning_rate': 0.0005, 'epoch': 4.1}\n",
      "{'loss': 0.4706, 'learning_rate': 0.0005, 'epoch': 4.1}\n",
      "{'loss': 0.457, 'learning_rate': 0.0005, 'epoch': 4.1}\n",
      "{'loss': 0.4614, 'learning_rate': 0.0005, 'epoch': 4.1}\n",
      "{'loss': 0.4316, 'learning_rate': 0.0005, 'epoch': 4.1}\n",
      "{'loss': 0.4905, 'learning_rate': 0.0005, 'epoch': 4.1}\n",
      "{'loss': 0.4294, 'learning_rate': 0.0005, 'epoch': 4.1}\n",
      "{'loss': 0.5394, 'learning_rate': 0.0005, 'epoch': 4.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed45f66f542a47648a00b0b55f41fc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5316388607025146, 'eval_accuracy': 0.7625360230547551, 'eval_f1': 0.7929127921588338, 'eval_precision': 0.7029857397504456, 'eval_recall': 0.909221902017291, 'eval_matthews_correlation': 0.5492394398958639, 'eval_auc': 0.7625360230547551, 'eval_runtime': 141.9362, 'eval_samples_per_second': 48.895, 'eval_steps_per_second': 3.058, 'epoch': 4.1}\n",
      "{'loss': 0.4044, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4443, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4109, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.5003, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4526, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4592, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4923, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4944, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4553, 'learning_rate': 0.0005, 'epoch': 5.0}\n",
      "{'loss': 0.4719, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.5096, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4453, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4896, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4384, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4885, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.5144, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4737, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4806, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4706, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4537, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4597, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.3666, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4521, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4803, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4439, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4676, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.38, 'learning_rate': 0.0005, 'epoch': 5.01}\n",
      "{'loss': 0.4342, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4507, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4487, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4347, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.48, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4376, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4487, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4462, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.469, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4843, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4858, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.5045, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4155, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4569, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.4895, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.5185, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.3782, 'learning_rate': 0.0005, 'epoch': 5.02}\n",
      "{'loss': 0.5067, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.3956, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4458, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4316, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4784, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4998, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4648, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4797, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4356, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4437, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.406, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4626, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.5113, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.5117, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4587, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.447, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4866, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4698, 'learning_rate': 0.0005, 'epoch': 5.03}\n",
      "{'loss': 0.4569, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.5488, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4652, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4553, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4479, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4386, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.553, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.5, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4545, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4633, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.5089, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4238, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4113, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4646, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4124, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4492, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4691, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4392, 'learning_rate': 0.0005, 'epoch': 5.04}\n",
      "{'loss': 0.4643, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4759, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4577, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4558, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4322, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4579, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.3692, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4997, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4338, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.5226, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4951, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4626, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4261, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4647, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4623, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4742, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.4657, 'learning_rate': 0.0005, 'epoch': 5.05}\n",
      "{'loss': 0.5, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4486, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4247, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4827, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4155, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4071, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.5228, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4478, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4467, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4772, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.449, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4886, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4486, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4558, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.3996, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4101, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4323, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.4752, 'learning_rate': 0.0005, 'epoch': 5.06}\n",
      "{'loss': 0.3715, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4155, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4651, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4448, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4897, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4554, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4608, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4736, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4492, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4374, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4177, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4683, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4273, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4653, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4723, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4684, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.5103, 'learning_rate': 0.0005, 'epoch': 5.07}\n",
      "{'loss': 0.4063, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4574, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4795, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4837, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4629, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.5143, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4762, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.5165, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4551, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4602, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4388, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.5412, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.499, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4388, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4911, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4312, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4281, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4543, 'learning_rate': 0.0005, 'epoch': 5.08}\n",
      "{'loss': 0.4582, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4917, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4967, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.49, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4459, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.419, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.465, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.3955, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4333, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4365, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4577, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4493, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4255, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4599, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.5079, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4587, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.452, 'learning_rate': 0.0005, 'epoch': 5.09}\n",
      "{'loss': 0.4768, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.4743, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.4163, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.4816, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.444, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.4418, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.3925, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.5219, 'learning_rate': 0.0005, 'epoch': 5.1}\n",
      "{'loss': 0.4013, 'learning_rate': 0.0005, 'epoch': 5.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21931ed19da459c8fe3e0ac75c8f788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49957406520843506, 'eval_accuracy': 0.7789625360230548, 'eval_f1': 0.7974650118827569, 'eval_precision': 0.7358674463937622, 'eval_recall': 0.8703170028818443, 'eval_matthews_correlation': 0.5674773913705552, 'eval_auc': 0.7789625360230548, 'eval_runtime': 141.9701, 'eval_samples_per_second': 48.884, 'eval_steps_per_second': 3.057, 'epoch': 5.1}\n",
      "{'loss': 0.4625, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.3707, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.5367, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.4057, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.4995, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.5017, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.4819, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.4559, 'learning_rate': 0.0005, 'epoch': 6.0}\n",
      "{'loss': 0.4745, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4844, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4555, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.5169, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4124, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4855, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4979, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4918, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4516, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.5067, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4472, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4262, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.3717, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4518, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4232, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4594, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4769, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.3931, 'learning_rate': 0.0005, 'epoch': 6.01}\n",
      "{'loss': 0.4009, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4461, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4305, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4366, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4452, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4622, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4256, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4645, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4115, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4814, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4823, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4386, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4578, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4448, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.5198, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.5092, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4151, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.4696, 'learning_rate': 0.0005, 'epoch': 6.02}\n",
      "{'loss': 0.3841, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.448, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4337, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4362, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4775, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.468, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4745, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4039, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4301, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4211, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4362, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4741, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.5103, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.433, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4258, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4726, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4478, 'learning_rate': 0.0005, 'epoch': 6.03}\n",
      "{'loss': 0.4341, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.5488, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4364, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4508, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4404, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4254, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.5612, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4672, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4478, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4432, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.5149, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4533, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.401, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4115, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4233, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.457, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4892, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4577, 'learning_rate': 0.0005, 'epoch': 6.04}\n",
      "{'loss': 0.4504, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.475, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.41, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4566, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4332, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4482, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.3981, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.461, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4203, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4822, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4946, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4702, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4345, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4122, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4722, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4544, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4777, 'learning_rate': 0.0005, 'epoch': 6.05}\n",
      "{'loss': 0.4681, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4605, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.3936, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4691, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.434, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.3705, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4952, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4884, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.377, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.48, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.3995, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4518, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4726, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4086, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4276, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.3921, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.4593, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.46, 'learning_rate': 0.0005, 'epoch': 6.06}\n",
      "{'loss': 0.3769, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.393, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4633, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4548, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4299, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4135, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.483, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4529, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4416, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4447, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.3945, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4907, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.3897, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4683, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4659, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.4288, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.5418, 'learning_rate': 0.0005, 'epoch': 6.07}\n",
      "{'loss': 0.3874, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4742, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.427, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4748, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4549, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.511, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.5039, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.497, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4481, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4733, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4348, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.504, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4965, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4598, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.5019, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4137, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4214, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4395, 'learning_rate': 0.0005, 'epoch': 6.08}\n",
      "{'loss': 0.4396, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4724, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.5078, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4921, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4422, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.3812, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4766, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.3774, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4493, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4334, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4575, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4368, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4466, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4286, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4916, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4845, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4614, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.4853, 'learning_rate': 0.0005, 'epoch': 6.09}\n",
      "{'loss': 0.463, 'learning_rate': 0.0005, 'epoch': 6.1}\n",
      "{'loss': 0.3685, 'learning_rate': 0.0005, 'epoch': 6.1}\n",
      "{'loss': 0.4873, 'learning_rate': 0.0005, 'epoch': 6.1}\n",
      "{'loss': 0.4092, 'learning_rate': 0.0005, 'epoch': 6.1}\n",
      "{'loss': 0.4221, 'learning_rate': 0.0005, 'epoch': 6.1}\n",
      "{'loss': 0.4477, 'learning_rate': 0.0005, 'epoch': 6.1}\n",
      "{'loss': 0.4949, 'learning_rate': 0.0005, 'epoch': 6.1}\n",
      "{'loss': 0.449, 'learning_rate': 0.0005, 'epoch': 6.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afac79308d334f34b6217f047bb89d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49980756640434265, 'eval_accuracy': 0.7757925072046109, 'eval_f1': 0.7949393779652083, 'eval_precision': 0.7323943661971831, 'eval_recall': 0.869164265129683, 'eval_matthews_correlation': 0.5614618568129566, 'eval_auc': 0.775792507204611, 'eval_runtime': 141.6751, 'eval_samples_per_second': 48.985, 'eval_steps_per_second': 3.063, 'epoch': 6.1}\n",
      "{'loss': 0.381, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.373, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.4834, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.4768, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.46, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.5106, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.468, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.4704, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.4452, 'learning_rate': 0.0005, 'epoch': 7.0}\n",
      "{'loss': 0.5195, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4939, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4467, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4107, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4389, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4997, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4691, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4469, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.5005, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4413, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4103, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4088, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.3564, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4299, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4762, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.447, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.3721, 'learning_rate': 0.0005, 'epoch': 7.01}\n",
      "{'loss': 0.4003, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.3985, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4607, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4369, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4214, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4593, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4119, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4427, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4158, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.5078, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4466, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4513, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4797, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4119, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4878, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4701, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4207, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4362, 'learning_rate': 0.0005, 'epoch': 7.02}\n",
      "{'loss': 0.4126, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4097, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4132, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4358, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4389, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.5066, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4099, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4263, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4393, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.3851, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4209, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4799, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.5116, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4968, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.404, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4193, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4586, 'learning_rate': 0.0005, 'epoch': 7.03}\n",
      "{'loss': 0.4012, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.5261, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4347, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4387, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4538, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4266, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.5618, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4449, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.5007, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4115, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4443, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4846, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.3925, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4302, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4248, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4554, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4616, 'learning_rate': 0.0005, 'epoch': 7.04}\n",
      "{'loss': 0.4027, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4802, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.3854, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.494, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4005, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.435, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4244, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4775, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4039, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4579, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.511, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4766, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4456, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4051, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4715, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4669, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4862, 'learning_rate': 0.0005, 'epoch': 7.05}\n",
      "{'loss': 0.4702, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4485, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.3924, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4736, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.42, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.3704, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4383, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4957, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4026, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4716, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4113, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4662, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.437, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4194, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4311, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4038, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4077, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4516, 'learning_rate': 0.0005, 'epoch': 7.06}\n",
      "{'loss': 0.4275, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.3547, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4245, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.474, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4183, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4264, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4599, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4744, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4505, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.3944, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.395, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4644, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4308, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4912, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4105, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4075, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4828, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4198, 'learning_rate': 0.0005, 'epoch': 7.07}\n",
      "{'loss': 0.4366, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4216, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4849, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4409, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.517, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.525, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4765, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.46, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.446, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4389, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4926, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4885, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4809, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4333, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4286, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4034, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4107, 'learning_rate': 0.0005, 'epoch': 7.08}\n",
      "{'loss': 0.4801, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4266, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4562, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4809, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4691, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.3892, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4804, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4158, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.3695, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4138, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4677, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4171, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4629, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.3744, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.5012, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4301, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4303, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.4736, 'learning_rate': 0.0005, 'epoch': 7.09}\n",
      "{'loss': 0.492, 'learning_rate': 0.0005, 'epoch': 7.1}\n",
      "{'loss': 0.3937, 'learning_rate': 0.0005, 'epoch': 7.1}\n",
      "{'loss': 0.4469, 'learning_rate': 0.0005, 'epoch': 7.1}\n",
      "{'loss': 0.3995, 'learning_rate': 0.0005, 'epoch': 7.1}\n",
      "{'loss': 0.4164, 'learning_rate': 0.0005, 'epoch': 7.1}\n",
      "{'loss': 0.4469, 'learning_rate': 0.0005, 'epoch': 7.1}\n",
      "{'loss': 0.4457, 'learning_rate': 0.0005, 'epoch': 7.1}\n",
      "{'loss': 0.4717, 'learning_rate': 0.0005, 'epoch': 7.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010f9cc1dfaa4051ba4d9f39663069ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49713948369026184, 'eval_accuracy': 0.7799711815561959, 'eval_f1': 0.7931735067045915, 'eval_precision': 0.7482749808331204, 'eval_recall': 0.8438040345821326, 'eval_matthews_correlation': 0.5645620301901673, 'eval_auc': 0.779971181556196, 'eval_runtime': 140.979, 'eval_samples_per_second': 49.227, 'eval_steps_per_second': 3.078, 'epoch': 7.1}\n",
      "{'loss': 0.4081, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.3421, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.4798, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.4348, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.4128, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.501, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.469, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.4531, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.4305, 'learning_rate': 0.0005, 'epoch': 8.0}\n",
      "{'loss': 0.5501, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4448, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4456, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.3866, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4714, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4955, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4587, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4375, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.5002, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4318, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.408, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4055, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4051, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.429, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4246, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4171, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4372, 'learning_rate': 0.0005, 'epoch': 8.01}\n",
      "{'loss': 0.4059, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4297, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.3939, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4497, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4357, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4635, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4106, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.435, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4145, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4414, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4522, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4591, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4593, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4017, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4838, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4554, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4201, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.4487, 'learning_rate': 0.0005, 'epoch': 8.02}\n",
      "{'loss': 0.3946, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4481, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4081, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4345, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4163, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4755, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4046, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4209, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4587, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.3562, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4177, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4235, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4878, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4925, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4119, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4106, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.4627, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.3898, 'learning_rate': 0.0005, 'epoch': 8.03}\n",
      "{'loss': 0.515, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4485, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4331, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.441, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.402, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4822, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4963, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4469, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4406, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4264, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4806, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4271, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.3952, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4352, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4171, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4489, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4119, 'learning_rate': 0.0005, 'epoch': 8.04}\n",
      "{'loss': 0.4243, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4359, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4162, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4549, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4059, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.3988, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4303, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4411, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.3909, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.432, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.5268, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4486, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4364, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.3773, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4643, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.408, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.5001, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4402, 'learning_rate': 0.0005, 'epoch': 8.05}\n",
      "{'loss': 0.4671, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.3477, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4472, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4266, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.3944, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.3838, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4946, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4008, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.3946, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4366, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4454, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4561, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.408, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4161, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.414, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.3954, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4343, 'learning_rate': 0.0005, 'epoch': 8.06}\n",
      "{'loss': 0.4601, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.3476, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.387, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4746, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.3911, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4059, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4517, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4732, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4151, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4109, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.3896, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.436, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4118, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4902, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4431, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4069, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4822, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.4336, 'learning_rate': 0.0005, 'epoch': 8.07}\n",
      "{'loss': 0.3966, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4214, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4495, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4844, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4837, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4997, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4567, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4651, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4378, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4505, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4556, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4975, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4737, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4436, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4129, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4059, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.3998, 'learning_rate': 0.0005, 'epoch': 8.08}\n",
      "{'loss': 0.4366, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4682, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4619, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4919, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4561, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.3781, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4322, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.446, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4019, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.3943, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4692, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4194, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.428, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.3887, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4934, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4046, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4374, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4555, 'learning_rate': 0.0005, 'epoch': 8.09}\n",
      "{'loss': 0.4835, 'learning_rate': 0.0005, 'epoch': 8.1}\n",
      "{'loss': 0.3877, 'learning_rate': 0.0005, 'epoch': 8.1}\n",
      "{'loss': 0.4531, 'learning_rate': 0.0005, 'epoch': 8.1}\n",
      "{'loss': 0.4, 'learning_rate': 0.0005, 'epoch': 8.1}\n",
      "{'loss': 0.4042, 'learning_rate': 0.0005, 'epoch': 8.1}\n",
      "{'loss': 0.4164, 'learning_rate': 0.0005, 'epoch': 8.1}\n",
      "{'loss': 0.4432, 'learning_rate': 0.0005, 'epoch': 8.1}\n",
      "{'loss': 0.4877, 'learning_rate': 0.0005, 'epoch': 8.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26ba3f5deef45fe938a0d4b00043988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5449955463409424, 'eval_accuracy': 0.7662824207492795, 'eval_f1': 0.7967418546365914, 'eval_precision': 0.7048780487804878, 'eval_recall': 0.9161383285302593, 'eval_matthews_correlation': 0.5582266411024245, 'eval_auc': 0.7662824207492795, 'eval_runtime': 141.2731, 'eval_samples_per_second': 49.125, 'eval_steps_per_second': 3.072, 'epoch': 8.1}\n",
      "{'loss': 0.3858, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.384, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4305, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4533, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4538, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4599, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4382, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4686, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4201, 'learning_rate': 0.0005, 'epoch': 9.0}\n",
      "{'loss': 0.4818, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.453, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4293, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4076, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4394, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4576, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4674, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4106, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4947, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4519, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.3937, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4101, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.3721, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4254, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4449, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4328, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.4007, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.326, 'learning_rate': 0.0005, 'epoch': 9.01}\n",
      "{'loss': 0.3981, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.3865, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4387, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4297, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4637, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.3822, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4102, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4139, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4243, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4499, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4603, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4541, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.3667, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4528, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4842, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.4125, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.3697, 'learning_rate': 0.0005, 'epoch': 9.02}\n",
      "{'loss': 0.413, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4228, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.382, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4416, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.414, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.442, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4447, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4384, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4024, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.3592, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4026, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4087, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4781, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4609, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4269, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4421, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.4523, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.3849, 'learning_rate': 0.0005, 'epoch': 9.03}\n",
      "{'loss': 0.5032, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4832, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.3998, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4363, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.376, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4429, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.5061, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4426, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4225, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4251, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4535, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4362, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.3325, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.441, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4295, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4199, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.4024, 'learning_rate': 0.0005, 'epoch': 9.04}\n",
      "{'loss': 0.444, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4597, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4067, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4479, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4137, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.3965, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4236, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.3759, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4476, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.442, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4708, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.489, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4205, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.3866, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4439, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4183, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4526, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.488, 'learning_rate': 0.0005, 'epoch': 9.05}\n",
      "{'loss': 0.4708, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.3419, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4587, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4303, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.3626, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.3429, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4991, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.3947, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.3603, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4528, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4121, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4242, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.3974, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4522, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.376, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4279, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.3814, 'learning_rate': 0.0005, 'epoch': 9.06}\n",
      "{'loss': 0.4176, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.3858, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.3575, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4529, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4226, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4485, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.3935, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4684, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4118, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.3892, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.3705, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4321, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4272, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.404, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4523, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4166, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4629, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.4558, 'learning_rate': 0.0005, 'epoch': 9.07}\n",
      "{'loss': 0.376, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4327, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4393, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4685, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4631, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4744, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4549, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4788, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4444, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4127, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.444, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.48, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4488, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4216, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.3907, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4097, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.3723, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.43, 'learning_rate': 0.0005, 'epoch': 9.08}\n",
      "{'loss': 0.4638, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.455, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4512, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4446, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.3652, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4098, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.3969, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4107, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.3866, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4328, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.3812, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4295, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4076, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.467, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4293, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4205, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4498, 'learning_rate': 0.0005, 'epoch': 9.09}\n",
      "{'loss': 0.4505, 'learning_rate': 0.0005, 'epoch': 9.1}\n",
      "{'loss': 0.4395, 'learning_rate': 0.0005, 'epoch': 9.1}\n",
      "{'loss': 0.388, 'learning_rate': 0.0005, 'epoch': 9.1}\n",
      "{'loss': 0.4271, 'learning_rate': 0.0005, 'epoch': 9.1}\n",
      "{'loss': 0.4118, 'learning_rate': 0.0005, 'epoch': 9.1}\n",
      "{'loss': 0.4273, 'learning_rate': 0.0005, 'epoch': 9.1}\n",
      "{'loss': 0.4161, 'learning_rate': 0.0005, 'epoch': 9.1}\n",
      "{'loss': 0.4889, 'learning_rate': 0.0005, 'epoch': 9.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648291aa30bd4a0bbd94b0457068fd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5484501719474792, 'eval_accuracy': 0.7755043227665706, 'eval_f1': 0.8015792154865004, 'eval_precision': 0.7181652213601095, 'eval_recall': 0.9069164265129683, 'eval_matthews_correlation': 0.5710858915916953, 'eval_auc': 0.7755043227665707, 'eval_runtime': 140.8109, 'eval_samples_per_second': 49.286, 'eval_steps_per_second': 3.082, 'epoch': 9.1}\n",
      "{'loss': 0.3467, 'learning_rate': 0.0005, 'epoch': 10.0}\n",
      "{'loss': 0.4065, 'learning_rate': 0.0005, 'epoch': 10.0}\n",
      "{'loss': 0.3958, 'learning_rate': 0.0005, 'epoch': 10.0}\n",
      "{'loss': 0.4631, 'learning_rate': 0.0005, 'epoch': 10.0}\n",
      "{'loss': 0.4223, 'learning_rate': 0.0005, 'epoch': 10.0}\n",
      "{'loss': 0.4253, 'learning_rate': 0.0005, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88000243bb954453b7c5fc496d9e0ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5414459705352783, 'eval_accuracy': 0.77492795389049, 'eval_f1': 0.8001535312180142, 'eval_precision': 0.7195121951219512, 'eval_recall': 0.9011527377521614, 'eval_matthews_correlation': 0.5682618796241644, 'eval_auc': 0.7749279538904899, 'eval_runtime': 140.5753, 'eval_samples_per_second': 49.369, 'eval_steps_per_second': 3.087, 'epoch': 10.0}\n",
      "{'train_runtime': 24742.4251, 'train_samples_per_second': 18.184, 'train_steps_per_second': 0.284, 'train_loss': 0.4874733863989286, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"One Epoch total steps: {}\".format(train_steps / epochs))\n",
    "train_res = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_for_debug:\n",
    "    print(trainer.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ac93eef5a9435886e2203193f3d712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7526 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6862de1c8d4c92aefab749275f5bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/941 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5461655855178833, 'eval_accuracy': 0.7499335636460271, 'eval_f1': 0.5639481000926784, 'eval_precision': 0.42433751743375175, 'eval_recall': 0.8404696132596685, 'eval_matthews_correlation': 0.4617012156429259, 'eval_auc': 0.7844171034379949, 'eval_runtime': 75.1986, 'eval_samples_per_second': 100.082, 'eval_steps_per_second': 12.514, 'epoch': 10.01}\n"
     ]
    }
   ],
   "source": [
    "testing=True\n",
    "if testing:\n",
    "    test_dataset = test_dataset.map(encode,load_from_cache_file=False, batch_size=batch_size,batched=True, remove_columns=columns_to_remove)  \n",
    "    trainer.model = AutoModelForSequenceClassification.from_pretrained(trainer.state.best_model_checkpoint).to('cuda') #\n",
    "    test_res = trainer.evaluate(eval_dataset=test_dataset.with_format(\"torch\"))\n",
    "    print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td></td></tr><tr><td>eval/auc</td><td></td></tr><tr><td>eval/f1</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/matthews_correlation</td><td></td></tr><tr><td>eval/precision</td><td></td></tr><tr><td>eval/recall</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.74993</td></tr><tr><td>eval/auc</td><td>0.78442</td></tr><tr><td>eval/f1</td><td>0.56395</td></tr><tr><td>eval/loss</td><td>0.54617</td></tr><tr><td>eval/matthews_correlation</td><td>0.4617</td></tr><tr><td>eval/precision</td><td>0.42434</td></tr><tr><td>eval/recall</td><td>0.84047</td></tr><tr><td>eval/runtime</td><td>75.1986</td></tr><tr><td>eval/samples_per_second</td><td>100.082</td></tr><tr><td>eval/steps_per_second</td><td>12.514</td></tr><tr><td>train/epoch</td><td>10.01</td></tr><tr><td>train/global_step</td><td>7050</td></tr><tr><td>train/learning_rate</td><td>0.0005</td></tr><tr><td>train/loss</td><td>0.4405</td></tr><tr><td>train/total_flos</td><td>1.1862367275348912e+17</td></tr><tr><td>train/train_loss</td><td>0.48956</td></tr><tr><td>train/train_runtime</td><td>14682.3198</td></tr><tr><td>train/train_samples_per_second</td><td>30.731</td></tr><tr><td>train/train_steps_per_second</td><td>0.48</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apache_jit/codebert_512_msg_</strong> at: <a href='https://wandb.ai/jit_defect/apache_jit/runs/s2kginll' target=\"_blank\">https://wandb.ai/jit_defect/apache_jit/runs/s2kginll</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_210019-s2kginll\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bfdea147fd3fde812f8377112128e9c479b40cdcf127ad60d7e7ec5b48ee1c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
